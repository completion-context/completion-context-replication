{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGdy4uJq1kSQ"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HNJ04EH1qdW"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output \n",
        "!pip install tensorflow==2.9 t5 tensorflow-text==2.9\n",
        "#!pip install -q t5 tensorflow-text==2.4.3\n",
        "#!pip install -q tensorflow-text==2.8.0rc0\n",
        "#!pip install -U tensorflow-gcs-config==2.9.1\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g65Qu6MF1x2W",
        "outputId": "2203db5d-3ed8-44e6-9151-cfa1bddb146a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "import functools\n",
        "import os\n",
        "import gin\n",
        "import tensorflow_gcs_config\n",
        "from google.colab import auth\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "import t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1MRzBLtex2",
        "outputId": "8e1588eb-6201-4cb3-fcb4-344367e9b9f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up GCS access...\n",
            "WARNING: auth.authenticate_user() will eventually stop supporting auth for Tensorflow on TPU devices. See auth.authenticate_service_account() instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU: grpc://10.49.36.146:8470\n"
          ]
        }
      ],
      "source": [
        "TOKENIZER_DIR = \"<bucket>\" #@param { type: \"string\" }\n",
        "if not TOKENIZER_DIR or TOKENIZER_DIR == \"gs://\": \n",
        "  raise ValueError(\"You must enter a TOKENIZER_DIR.\")\n",
        "\n",
        "print(\"Setting up GCS access...\")\n",
        "os.environ['USE_AUTH_EPHEM'] = '0'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set credentials for GCS reading/writing from Colab and TPU.\n",
        "TPU_TOPOLOGY = \"2x2\"\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  TPU_ADDRESS = tpu.get_master()\n",
        "  print('Running on TPU:', TPU_ADDRESS)\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "#tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "\n",
        "#LOGGING\n",
        "tf.get_logger().propagate = False\n",
        "py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0kxnD0T8EzI"
      },
      "source": [
        "# Load Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5h4PkSo_Kus",
        "outputId": "518556e8-74e6-4545-ece4-fdd1a017eda6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://bucket_context/eighth_experiment/code.model\n",
            "gs://bucket_context/eighth_experiment/code.vocab\n"
          ]
        }
      ],
      "source": [
        "vocab_model_path = 'code.model file'\n",
        "vocab_path = 'code.vocab file'\n",
        "print(vocab_model_path)\n",
        "print(vocab_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wq4YkN9_UkO"
      },
      "outputs": [],
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "num_special_mask_tokens = 100 #@param {type: \"integer\"}\n",
        "\n",
        "def load_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, num_special_mask_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzX8GZjGVVne"
      },
      "outputs": [],
      "source": [
        "# change config file based on the finetuning context you want to perform\n",
        "config=\"call\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3yMW-___hYd"
      },
      "source": [
        "# Prepare Dataset for T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "outputs": [],
      "source": [
        "# save each dataset in a folder named ft_ followed by the current context\n",
        "train_path = 'gs://bucket_context/eighth_experiment/ft_{}/train.tsv'.format(config) #@param { type: \"string\" }\n",
        "eval_path = 'gs://bucket_context/eighth_experiment/ft_{}/eval.tsv'.format(config) #@param { type: \"string\" }\n",
        "test_path = 'gs://bucket_context/eighth_experiment/ft_{}/test.tsv'.format(config) #@param { type: \"string\" }\n",
        "finetune_datasets_paths = {\n",
        "    \"train\":      train_path,\n",
        "    \"validation\": eval_path\n",
        "}\n",
        "\n",
        "# Useful when multi-task training \n",
        "# num_input_examples = dict(train=106382, validation=12020) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0NTLbyXvkCs"
      },
      "outputs": [],
      "source": [
        "def load_dataset(split, shuffle_files=True):\n",
        "  \"\"\"\n",
        "  Function to load .tsv dataset as a tf.data.Dataset in TensorFlow\n",
        "  \"\"\"\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(finetune_datasets_paths[split])\n",
        "  ds = ds.map(functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                          field_delim=\"\\t\", use_quote_delim=False)\n",
        "                          , \n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J4_UFsVmSPk"
      },
      "source": [
        "### A few examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__RNWuimAxS9",
        "outputId": "0b4cff6e-df90-459e-bbf1-55ffecc565df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'<extra_id_0><nl>return MapHandlerRegistration.addHandler(this, MapEventType.SHADOW_CHANGED, handler,<nl>new ShadowChangeEventFormatter());<nl>} <sep> public final HandlerRegistration addAnimationChangeHandler(AnimationChangeMapHandler handler) {<nl>return MapHandlerRegistration.addHandler(this, MapEventType.ANIMATION_CHANGED, handler,<nl>new AnimationChangeEventFormatter());<nl>}', 'output': b'public final HandlerRegistration addShadowChangeHandler(ShadowChangeMapHandler handler) {'}\n",
            "{'input': b'public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateVolumeGroupBackupRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(<nl>request.getVolumeGroupBackupId(), \"volumeGroupBackupId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateVolumeGroupBackupDetails(),<nl>\"updateVolumeGroupBackupDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"volumeGroupBackups\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getVolumeGroupBackupId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl><extra_id_0><nl>}<nl>return ib;<nl>} <sep> public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.DeleteInternetGatewayRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(request.getIgId(), \"igId must not be blank\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"internetGateways\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getIgId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl>}<nl>return ib;<nl>}', 'output': b'if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);'}\n",
            "{'input': b'public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateVolumeGroupBackupRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(<nl>request.getVolumeGroupBackupId(), \"volumeGroupBackupId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateVolumeGroupBackupDetails(),<nl>\"updateVolumeGroupBackupDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"volumeGroupBackups\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getVolumeGroupBackupId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl><extra_id_0><nl>return ib;<nl>} <sep> public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateDrgAttachmentRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(request.getDrgAttachmentId(), \"drgAttachmentId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateDrgAttachmentDetails(), \"updateDrgAttachmentDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"drgAttachments\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getDrgAttachmentId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl>}<nl>return ib;<nl>}', 'output': b'}'}\n",
            "{'input': b'<extra_id_0><nl>public OptionalInt findSingle() {<nl>if (iterator.hasNext()) {<nl>int singleCandidate = iterator.nextInt();<nl>if (iterator.hasNext()) {<nl>throw new IllegalStateException(\"IntStream contains more than one element\");<nl>} else {<nl>return OptionalInt.of(singleCandidate);<nl>}<nl>} else {<nl>return OptionalInt.empty();<nl>}<nl>} <sep> @NotNull<nl>public Optional<T> findSingle() {<nl>if (iterator.hasNext()) {<nl>T singleCandidate = iterator.next();<nl>if (iterator.hasNext()) {<nl>throw new IllegalStateException(\"Stream contains more than one element\");<nl>} else {<nl>return Optional.of(singleCandidate);<nl>}<nl>} else {<nl>return Optional.empty();<nl>}<nl>}', 'output': b'@NotNull'}\n",
            "{'input': b'public byte[] getData() {<nl>if (packet != null) {<nl>Object dataSerializer = readObject(0, NMSUtils.packetDataSerializerClass);<nl>WrappedPacket byteBufWrapper = new WrappedPacket(new NMSPacket(dataSerializer));<nl>Object byteBuf = byteBufWrapper.readObject(0, NMSUtils.byteBufClass);<nl>return PacketEvents.get().getByteBufUtil().getBytes(byteBuf);<nl><extra_id_0><nl>return data;<nl>}<nl>} <sep> public byte[] getData() {<nl>if (packet != null) {<nl>switch (constructorMode) {<nl>case 0:<nl>return readByteArray(0);<nl>case 1:<nl>case 2:<nl>return PacketEvents.get().getByteBufUtil().getBytes(getBuffer());<nl>default:<nl>return new byte[0];<nl>}<nl>}<nl>return data;<nl>}', 'output': b'} else {'}\n"
          ]
        }
      ],
      "source": [
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(load_dataset(\"train\").take(5)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsbHi89ZA5-j"
      },
      "source": [
        "# Dataset Prepocessing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bJZPQgjxKZ1"
      },
      "outputs": [],
      "source": [
        "from tensorflow_datasets.core.utils.type_utils import Shape\n",
        "\n",
        "def preprocessing(ds):\n",
        "  \"\"\"\n",
        "  Preprocess function to convert the tf.data.Dataset into a text-to-text format,\n",
        "  with both inputs and targets fields.\n",
        "  Param: tf.data.Dataset\n",
        "  Return: text-to-text format\n",
        "  \"\"\"\n",
        "  prefix = '' # no prefix for pretraining\n",
        "  def to_inputs_and_targets(ex):\n",
        "    x_input = tf.strings.strip(prefix + ex['input'])\n",
        "    y_label = tf.strings.strip(ex['output']) \n",
        "    inputs = tf.strings.join([x_input], separator=' ')\n",
        "    class_label = tf.strings.join([y_label], separator=' ')\n",
        "    return {'inputs': inputs, 'targets': class_label}\n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vymEYLbQCBRY"
      },
      "source": [
        "### A few examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOyas1ZqBVgE",
        "outputId": "b0e25484-b31c-4182-8b32-aa87794f6c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed train examples...\n",
            "{'inputs': b'<extra_id_0><nl>return MapHandlerRegistration.addHandler(this, MapEventType.SHADOW_CHANGED, handler,<nl>new ShadowChangeEventFormatter());<nl>} <sep> public final HandlerRegistration addAnimationChangeHandler(AnimationChangeMapHandler handler) {<nl>return MapHandlerRegistration.addHandler(this, MapEventType.ANIMATION_CHANGED, handler,<nl>new AnimationChangeEventFormatter());<nl>}', 'targets': b'public final HandlerRegistration addShadowChangeHandler(ShadowChangeMapHandler handler) {'}\n",
            "{'inputs': b'public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateVolumeGroupBackupRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(<nl>request.getVolumeGroupBackupId(), \"volumeGroupBackupId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateVolumeGroupBackupDetails(),<nl>\"updateVolumeGroupBackupDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"volumeGroupBackups\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getVolumeGroupBackupId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl><extra_id_0><nl>}<nl>return ib;<nl>} <sep> public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.DeleteInternetGatewayRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(request.getIgId(), \"igId must not be blank\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"internetGateways\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getIgId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl>}<nl>return ib;<nl>}', 'targets': b'if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);'}\n",
            "{'inputs': b'public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateVolumeGroupBackupRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(<nl>request.getVolumeGroupBackupId(), \"volumeGroupBackupId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateVolumeGroupBackupDetails(),<nl>\"updateVolumeGroupBackupDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"volumeGroupBackups\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getVolumeGroupBackupId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl><extra_id_0><nl>return ib;<nl>} <sep> public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateDrgAttachmentRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(request.getDrgAttachmentId(), \"drgAttachmentId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateDrgAttachmentDetails(), \"updateDrgAttachmentDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"drgAttachments\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getDrgAttachmentId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl>}<nl>return ib;<nl>}', 'targets': b'}'}\n",
            "{'inputs': b'<extra_id_0><nl>public OptionalInt findSingle() {<nl>if (iterator.hasNext()) {<nl>int singleCandidate = iterator.nextInt();<nl>if (iterator.hasNext()) {<nl>throw new IllegalStateException(\"IntStream contains more than one element\");<nl>} else {<nl>return OptionalInt.of(singleCandidate);<nl>}<nl>} else {<nl>return OptionalInt.empty();<nl>}<nl>} <sep> @NotNull<nl>public Optional<T> findSingle() {<nl>if (iterator.hasNext()) {<nl>T singleCandidate = iterator.next();<nl>if (iterator.hasNext()) {<nl>throw new IllegalStateException(\"Stream contains more than one element\");<nl>} else {<nl>return Optional.of(singleCandidate);<nl>}<nl>} else {<nl>return Optional.empty();<nl>}<nl>}', 'targets': b'@NotNull'}\n",
            "{'inputs': b'public byte[] getData() {<nl>if (packet != null) {<nl>Object dataSerializer = readObject(0, NMSUtils.packetDataSerializerClass);<nl>WrappedPacket byteBufWrapper = new WrappedPacket(new NMSPacket(dataSerializer));<nl>Object byteBuf = byteBufWrapper.readObject(0, NMSUtils.byteBufClass);<nl>return PacketEvents.get().getByteBufUtil().getBytes(byteBuf);<nl><extra_id_0><nl>return data;<nl>}<nl>} <sep> public byte[] getData() {<nl>if (packet != null) {<nl>switch (constructorMode) {<nl>case 0:<nl>return readByteArray(0);<nl>case 1:<nl>case 2:<nl>return PacketEvents.get().getByteBufUtil().getBytes(getBuffer());<nl>default:<nl>return new byte[0];<nl>}<nl>}<nl>return data;<nl>}', 'targets': b'} else {'}\n"
          ]
        }
      ],
      "source": [
        "print(\"A few preprocessed train examples...\")\n",
        "sample = tfds.as_numpy(preprocessing(load_dataset(\"train\").take(5)))\n",
        "for ex in sample:\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OkQeLeh8Rst"
      },
      "source": [
        "# Creating Task and Mixture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PobLvzL18zzR",
        "outputId": "51b7bf63-93b2-4d58-d185-c317cfdc80a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seqio.dataset_providers.Mixture at 0x7ff7efbafa00>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=load_vocabulary(), add_eos=True, required=False),\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=load_vocabulary(), add_eos=True)\n",
        "    }\n",
        "\n",
        "TASK_NAME = \"ft\" #@param{ type : \"string\"}\n",
        "\n",
        "# TASK\n",
        "t5.data.TaskRegistry.remove(TASK_NAME)\n",
        "t5.data.TaskRegistry.add(\n",
        "    TASK_NAME,\n",
        "    # Function which returns a tf.data.Dataset\n",
        "    dataset_fn=load_dataset,\n",
        "    splits=[\"train\",\"validation\"],\n",
        "    # List of functions that preprocess the input tf.data.Dataset\n",
        "    text_preprocessor=[preprocessing],\n",
        "    # Accuracy is used as evaluation metric\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, helps for mixing and auto-caching\n",
        "    # num_input_examples=num_input_examples,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES\n",
        ")\n",
        "\n",
        "MIXTURE_NAME = \"task\" #@param{ type : \"string\"}\n",
        "\n",
        "# MIXTURE\n",
        "t5.data.MixtureRegistry.remove(MIXTURE_NAME)\n",
        "t5.data.MixtureRegistry.add(\n",
        "    MIXTURE_NAME,\n",
        "    # List of tasks\n",
        "    [TASK_NAME],\n",
        "    default_rate=1.0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwqLrVdGB6yy"
      },
      "source": [
        "### A few examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVHcIrjkA93r",
        "outputId": "2ace59f6-73df-43da-b680-23940627e4e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Using an uncached FunctionDataset for training is not recommended since it often results in insufficient shuffling on restarts, resulting in overfitting. It is highly recommended that you cache this task before training with it or use a data source that supports lower-level shuffling (e.g., FileDataSource).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'@Override<nl>@SuppressWarnings(\"unchecked\")<nl>public int doEndTag() throws JspException {<nl>// At this point, all setters have been called and the staging<nl>// configuration map should have been filled with user configuration<nl>// The user configuration can now be applied to the default<nl>// configuration<nl><extra_id_0><nl>// Once all configuration are merged, they can be processed<nl>OptionUtils.processOptions(this.table.getTableConfiguration().getOptions(), this.request);<nl>// The table is being exported<nl>if (ExportUtils.isTableBeingExported(this.request, this.table)) {<nl>return setupExport();<nl>}<nl>// The table must be generated and displayed<nl>else {<nl>if (request.getAttribute(DatatableComponent.DDL_DT_REQUESTATTR_TABLES) == null) {<nl>List<HtmlTable> htmlTables = new ArrayList<HtmlTable>();<nl>htmlTables.add(table);<nl>request.setAttribute(DatatableComponent.DDL_DT_REQUESTATTR_TABLES, htmlTables);<nl>}<nl>else {<nl>List<HtmlTable> htmlTables = (List<HtmlTable>) request<nl>.getAttribute(DatatableComponent.DDL_DT_REQUESTATTR_TABLES);<nl>htmlTables.add(table);<nl>}<nl>// ConfigUtils.storeTableInRequest(this.request, this.table);<nl>return setupHtmlGeneration();<nl>}<nl>} <sep> @Override<nl>public int doStartTag() throws JspException {<nl>this.iterationNumber = 1; // Just used to identify the first row (header)<nl>this.request = (HttpServletRequest) this.pageContext.getRequest();<nl>this.response = (HttpServletResponse) this.pageContext.getResponse();<nl>this.table = new HtmlTable(this.id, this.request, this.response, this.confGroup, this.dynamicAttributes);<nl>this.request.setAttribute(TableConfiguration.class.getCanonicalName(), this.table.getTableConfiguration());<nl>// The table data are loaded using an AJAX source<nl>if (SOURCE_AJAX.equals(this.dataSourceType)) {<nl>this.table.addHeaderRow();<nl>return EVAL_BODY_BUFFERED;<nl>}<nl>// The table data are loaded using a DOM source (Collection)<nl>else if (SOURCE_DOM.equals(this.dataSourceType)) {<nl>this.table.addHeaderRow();<nl>return processIteration();<nl>}<nl>// Never reached<nl>return SKIP_BODY;<nl>}', 'inputs': array([   20,  2913,     7,  4479,   503,  1084,   682,    30,   349,\n",
            "           7,  4943,    38, 29721,   842,    56,  8837,    13,     7,\n",
            "        8428,  9639,    36,   770,   101,   209, 20449,   430,   805,\n",
            "        1089,   100,    25, 16047,     7,  8428,   370,   156,   365,\n",
            "         430,   805,  8626,   109,   262,   370,     7,  8428,   113,\n",
            "         262,   370,   286,   926,    89,  3745,    37,    25,   222,\n",
            "           7,  8428,   370,     7,  2029, 22479,    18,   421,  1678,\n",
            "        1047,     7,  8428, 14544,   209,   370,   231,  2837,   101,\n",
            "        1827,   286,    89,  2466,     7,   884,   347,    35,  4359,\n",
            "         436,   325,  2189,    35,  1797,    35,   438,   320,   212,\n",
            "        2715,   438,   436,  5555,    36,    35,  2982,   908,     7,\n",
            "        8428,   113,   359,    47,  1549, 11538,     7,  1484,     8,\n",
            "        3514,   347,    35,  1022,   320, 17293, 14965,   325,  2189,\n",
            "          35,  2982,   101,    36,    35,  1797,  5445,    13,     7,\n",
            "        2930,  1897,  3514,  2388,     7,  2977,     7,  8428,   113,\n",
            "         359,   407,    89,  1588,   100,  8498,     7, 13561,    13,\n",
            "           7,  1484,     8,  2982,    35,   438,   380,   325,   139,\n",
            "        1797,   534,    35, 15378,    18,  7204,    18,  2596,  5118,\n",
            "          18, 26581,   349,    41,    27,   349,    13,     7,   108,\n",
            "        2029,  2337,   320,  1047,  1832,  3701,    15,    23,   199,\n",
            "        2029,  2337,   320,  1047,  2388,     7,  2221,  3701,    35,\n",
            "        1751,   325,  1797,   908,     7,  2982,    35,   730,   380,\n",
            "         325,   139,  1797,   534,    35, 15378,    18,  7204,    18,\n",
            "        2596,  5118,    18, 26581,   101,  1832,  3701,   908,     7,\n",
            "        2977,     7, 13561,    13,     7,   108,  2029,  2337,   320,\n",
            "        1047,  1832,  3701,    15,     8,   108,  2029,  2337,   320,\n",
            "       27154,    73,     7,    35,   438,   380,   325,   139,  1797,\n",
            "         534,    35, 15378,    18,  7204,    18,  2596,  5118,    18,\n",
            "       26581,   908,     7,  2221,  3701,    35,  1751,   325,  1797,\n",
            "         908,     7,  2977,     7,  8428, 15803,    35,  3911,   320,\n",
            "         375,    99,   325,  2189,    35,  2982,   101,    36,    35,\n",
            "        1797,   908,     7,  2930,  1897,  2337,  5858,  2388,     7,\n",
            "        2977,     7,  2977,    19,    28,  8100,  1047,    20,  2913,\n",
            "           7,  4943,    38, 23440,   842,    56,  8837,    13,     7,\n",
            "        2189,    35, 31467,   599,    15,    63,   785,    34, 10500,\n",
            "         439,    37,  8693,    25,   268,   403,     8,  5231,   349,\n",
            "           7,  2189,    35,  2982,    15,     8, 14565,    99,   349,\n",
            "          36,    35,  3022,   117,    35,   438,    99,  2388,     7,\n",
            "        2189,    35,  3203,    15,     8, 14565,   219,   349,    36,\n",
            "          35,  3022,   117,    35,   438,   219,  2388,     7,  2189,\n",
            "          35,  1797,    15,    23,  3963,   320,   325,  2189,    35,\n",
            "         421,   101,    36,    35,  2982,   101,    36,    35,  3203,\n",
            "         101,    36,    35,  5286,   301,   101,    36,    35, 20089,\n",
            "         633,   908,     7,  2189,    35,  2982,    35,   730,   380,\n",
            "         325,   320,   212,    35,  1270,    35,  3909,  5555,    36,\n",
            "          35,  1797,    35,   438,   320,   212,  3731,     7,  8428,\n",
            "         113,   359,   116,   231,  2239,   638,   151, 28016,   215,\n",
            "           7,  1484,     8,  5588,    18,   383,  1097,   383,   419,\n",
            "          35,  7358,   325,  2189,    35, 20624,    64,  5445,    13,\n",
            "           7,  2189,    35,  1797,    35,  1751,   520,   688,  2388,\n",
            "           7,  2930, 17222,    18, 10130,    18,  5216,  1135,   785,\n",
            "           7,  2977,     7,  8428,   113,   359,   116,   231,  2239,\n",
            "         638,    49,  4798,   215,     8,   710,   349,     7, 13561,\n",
            "          16,     8,  5588,    18, 10973,    35,  7358,   325,  2189,\n",
            "          35, 20624,    64,  5445,    13,     7,  2189,    35,  1797,\n",
            "          35,  1751,   520,   688,  2388,     7,  2930,   309,  6522,\n",
            "        2388,     7,  2977,     7,  8428, 11264,  5213,     7,  2930,\n",
            "        8420,    18, 10130,   785,     7,  2977,     1], dtype=int32), 'targets_pretokenized': b'this.table.getTableConfiguration().getOptions().putAll(this.stagingOptions);', 'targets': array([   36,    35,  1797,    35,   438,   320,   212,  2715,   438,\n",
            "         436,  2715,  5059,   769,   325,  2189,    35,  2074, 21203,\n",
            "         436,   908,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public Map<String, String> getAsMap(String key, Map<String, String> def) {<nl>Map<String, String> returnMap = new HashMap<String, String>(def);<nl>String val = get(key);<nl>try {<nl>Map<String, String> result = Tools.convertStringToMap(val, \"=\", \" \", true);<nl>returnMap.putAll(result);<nl><extra_id_0><nl>} catch (RuntimeException e) {<nl>return def;<nl>}<nl>} <sep> private static Map<String, String> decodeParametersFromJSON(String json) {<nl>try {<nl>JSONParser parser = new JSONParser();<nl>JSONObject root = (JSONObject)parser.parse(json);<nl>Map<String, String> result = new HashMap<>();<nl>for (Object key : root.keySet()) {<nl>result.put((String)key, (String)root.get(key));<nl>}<nl>return result;<nl>} catch (Exception ex) {<nl>return new HashMap<>();<nl>}<nl>}', 'inputs': array([   29,   114,  2029,   196,   101,    26,  1047,    31, 11003,\n",
            "         325,   196,    86,   101,   114,  2029,   196,   101,    26,\n",
            "        1047,  1385,   349,    13,     7,   136,  2029,   196,   101,\n",
            "          26,  1047,    17,   136,    15,    23,   519,  2029,   196,\n",
            "         101,    26,  1047,   325,  3993,   908,     7,   196,   427,\n",
            "          15,    31,   325,  1173,   908,     7,  9649,    13,     7,\n",
            "         136,  2029,   196,   101,    26,  1047,    69,    15, 18271,\n",
            "          35, 12197,   196,  9337,   325,  2875,   101,  3905,   101,\n",
            "          22,   989,    85,   908,     7,  2930,   136,    35,  5059,\n",
            "         769,   325,  4337,   908,     7,  2029, 22479,    18,   421,\n",
            "        1678,  1047,     7,  2977,    83,     8,   414,    52,   349,\n",
            "          13,     7,  2930,  1385,   785,     7,  2977,     7,  2977,\n",
            "          19,    28,  8100,  1047,    66,    62,   114,  2029,   196,\n",
            "         101,    26,  1047,   961,   524,   310,  1518,   325,   196,\n",
            "         449,   349,    13,     7,  9649,    13,     7,  1518,   684,\n",
            "         750,    15,    23,   609,   684,  2388,     7, 12401,   411,\n",
            "          15,     8, 12401,   349,  5640,    35,  5988,   325,  2336,\n",
            "         908,     7,   136,  2029,   196,   101,    26,  1047,    69,\n",
            "          15,    23,   519, 26121,  2388,     7,  3470,     8,   200,\n",
            "          86,    45,   411,    35,  1173,   239,  5799,    13,     7,\n",
            "        4337,    35,  5059, 12253,   196,   349,  1173,   101,     8,\n",
            "         196,   349,  4611,    35,   438,   325,  1173,  4684,     7,\n",
            "        2977,     7,  2930,    69,   785,     7,  2977,    83,     8,\n",
            "          42,   246,   349,    13,     7,  2930,    23,   519, 26121,\n",
            "        2388,     7,  2977,     7,  2977,     1], dtype=int32), 'targets_pretokenized': b'return returnMap;', 'targets': array([ 17,  17, 136, 785,   1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'@EventHandler(priority = EventPriority.NORMAL)<nl>public void signChange(SignChangeEvent event) {<nl>if (!event.getPlayer().hasPermission(\"mobarena.setup.leaderboards\")) {<nl>return;<nl>}<nl>if (!event.getLine(0).startsWith(\"[MA]\")) {<nl>return;<nl>}<nl>String text = event.getLine(0).substring((4));<nl>Arena arena;<nl>Stats stat;<nl>if ((arena = am.getArenaWithName(text)) != null) {<nl>arena.getEventListener().onSignChange(event);<nl><extra_id_0><nl>}<nl>else if ((stat = Stats.getByShortName(text)) != null) {<nl>setSignLines(event, ChatColor.GREEN + \"\", \"\", ChatColor.AQUA + stat.getFullName(), \"---------------\");<nl>am.getGlobalMessenger().tell(event.getPlayer(), \"Stat sign created.\");<nl>}<nl>} <sep> @EventHandler(priority = EventPriority.NORMAL)<nl>public void onEventNormal(PlayerLoginEvent event) {<nl>if (!event.getResult().equals(PlayerLoginEvent.Result.ALLOWED)) {<nl>DiscordSRV.debug(Debug.REQUIRE_LINK, \"PlayerLoginEvent event result for \" + event.getPlayer().getName() + \" = \" + event.getResult() + \", skipping\");<nl>return;<nl>}<nl>check(event.getClass().getSimpleName(), EventPriority.NORMAL, event.getPlayer().getName(), event.getPlayer().getUniqueId(), event.getAddress().getHostAddress(), (result, message) -> event.disallow(PlayerLoginEvent.Result.valueOf(result), message));<nl>}', 'inputs': array([   20,  7612,   325, 15154,    15,  1109,  3593,    35, 11730,\n",
            "         349,     7,  4943,    48,  2605,  1281,   325,  4717,  6309,\n",
            "         248,   349,    13,     7,  1484,     8,  1652,  3674,    35,\n",
            "         438,  6285,  2715,  5709,  1465,  1084,  4175,  3398, 18071,\n",
            "          35, 23205,    35,  2687,  4126,   315, 16774,    28,    30,\n",
            "        5445,    13,     7,  2930,   785,     7,  2977,     7,  1484,\n",
            "           8,  1652,  3674,    35,   438,   672, 20603,    35,  2071,\n",
            "        5151,  1084,  1862,  8979,  2276,  5445,    13,     7,  2930,\n",
            "         785,     7,  2977,     7,   196,   299,    15,   248,    35,\n",
            "         438,   672, 20603,    35, 23898, 12253,   376,  4684,     7,\n",
            "       10994,  5457,   231,  5457,   785,     7,  1060,  2961,   785,\n",
            "           7,  1484,     8,   325,  2253, 18071,    15,  8115,    35,\n",
            "         438, 10994,  5457, 18950,   325,  1831,  5445,    53,    27,\n",
            "         349,    13,     7,  2253, 18071,    35,   438,  3012,  2715,\n",
            "        1312,  4717,  1281,   325,  3674,   908,     7,  2029, 22479,\n",
            "          18,   421,  1678,  1047,     7,  2977,     7, 13561,    16,\n",
            "           8,   325, 14871,    15,  7368,    35,   438,   532, 16112,\n",
            "         325,  1831,  5445,    53,    27,   349,    13,     7,   730,\n",
            "        4717,  2914,   325,  3674,   101, 12450,   992,    35, 31640,\n",
            "          32,   400,   101,   400,   101, 12450,   992,    35,   383,\n",
            "       27723,    32,  2961,    35,   438,  9586,  5555,    22, 18026,\n",
            "         908,     7,  3248,    35,   438,  2532, 21528,  2715,   154,\n",
            "        7225,   325,  3674,    35,   438,  6285,  5555,    22,  3582,\n",
            "        2605,   838,    35,  3918,     7,  2977,     7,  2977,    19,\n",
            "          28,  8100,  1047,    20,  7612,   325, 15154,    15,  1109,\n",
            "        3593,    35, 11730,   349,     7,  4943,    48, 14414,  6562,\n",
            "         325,  6285,  2952,   259,   248,   349,    13,     7,  1484,\n",
            "           8,  1652,  3674,    35,   438,   131,  2715,  7358,   325,\n",
            "        6285,  2952,   259,    35,   131,    35,  9943,  5445,    13,\n",
            "           7, 20339, 10792, 10249,   667,    35,  6410,   325,  3691,\n",
            "          35, 23627,    18,  7403,   101,    22,  6285,  2952,   259,\n",
            "         248,    69,    44,    22,    32,   248,    35,   438,  6285,\n",
            "        2715, 10759,   842,    32,    22,    15,    22,    32,   248,\n",
            "          35,   438,   131,   842,    32,   989, 12184,  3918,     7,\n",
            "        2930,   785,     7,  2977,     7,  3104,   325,  3674,    35,\n",
            "       17413,  2715,   438, 11351,  5555,  1109,  3593,    35, 11730,\n",
            "         101,   248,    35,   438,  6285,  2715, 10759,  5555,   248,\n",
            "          35,   438,  6285,  2715,   438,  8502,  5555,   248,    35,\n",
            "         438,   578,  2715,   438,  1258,   578,  5555,     8,  4337,\n",
            "         101,   160,   349,   217,   248,    35, 12551, 12080,   325,\n",
            "        6285,  2952,   259,    35,   131,    35, 15835,   325,  4337,\n",
            "        3341,   160,  4684,     7,  2977,     1], dtype=int32), 'targets_pretokenized': b'setSignLines(event, ChatColor.GREEN + \"MobArena\", ChatColor.YELLOW + arena.configName(), ChatColor.AQUA + \"Players\", \"---------------\");', 'targets': array([   58,  4717,  2914,   325,  3674,   101, 12450,   992,    35,\n",
            "       31640,    32,    22,   870,  6505, 10994,  5457,  4597, 12450,\n",
            "         992,    35,   574,  3778, 14090,    32,   231,  5457,    35,\n",
            "        2504,    77,  5555, 12450,   992,    35,   383, 27723,    32,\n",
            "          22,  6285,    28,  4597,    22, 18026,   908,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'private boolean fetchAndStoreDelta() throws Throwable {<nl>long currGeneration = fetchRegistryGeneration.get();<nl>Applications delta = fetchRemoteRegistry(true);<nl>if (delta == null) {<nl>logger.error(\"The delta is null for some reason. Not storing this information\");<nl>} else if (fetchRegistryGeneration.compareAndSet(currGeneration, currGeneration + 1)) {<nl>this.applicationsDelta.set(delta);<nl>} else {<nl>delta = null; // set the delta to null so we don\\'t use it<nl>logger.warn(\"Not updating delta as another thread is updating it already\");<nl>}<nl>if (delta == null) {<nl>logger.warn(\"The server does not allow the delta revision to be applied because it is not \"<nl>+ \"safe. Hence got the full registry.\");<nl>return storeFullRegistry();<nl>} else {<nl>String reconcileHashCode = \"\";<nl>if (fetchRegistryUpdateLock.tryLock()) {<nl>try {<nl>updateDelta(delta);<nl>reconcileHashCode = getApplications().getReconcileHashCode();<nl>} finally {<nl>fetchRegistryUpdateLock.unlock();<nl>}<nl>} else {<nl>logger.warn(\"Cannot acquire update lock, aborting updateDelta operation of fetchAndStoreDelta\");<nl>}<nl>// There is a diff in number of instances for some reason<nl>if (!reconcileHashCode.equals(delta.getAppsHashCode())) {<nl>deltaMismatches++;<nl>return reconcileAndLogDifference(delta, reconcileHashCode);<nl><extra_id_0><nl>}<nl>}<nl>return delta != null;<nl>} <sep> private boolean fetchRegistry() {<nl>boolean success;<nl>Stopwatch tracer = fetchRegistryTimer.start();<nl>try {<nl>// If the delta is disabled or if it is the first time, get all applications<nl>if (serverConfig.shouldDisableDeltaForRemoteRegions()<nl>|| (getApplications() == null)<nl>|| (getApplications().getRegisteredApplications().size() == 0)) {<nl>logger.info(\"Disable delta property : {}\", serverConfig.shouldDisableDeltaForRemoteRegions());<nl>logger.info(\"Application is null : {}\", getApplications() == null);<nl>logger.info(\"Registered Applications size is zero : {}\", getApplications().getRegisteredApplications().isEmpty());<nl>success = storeFullRegistry();<nl>} else {<nl>success = fetchAndStoreDelta();<nl>}<nl>logTotalInstances();<nl>} catch (Throwable e) {<nl>logger.error(\"Unable to fetch registry information from the remote registry {}\", this.remoteRegionURL, e);<nl>return false;<nl>} finally {<nl>if (tracer != null) {<nl>tracer.stop();<nl>}<nl>}<nl>if (success) {<nl>timeOfLastSuccessfulRemoteFetch = System.currentTimeMillis();<nl>}<nl>return success;<nl>}', 'inputs': array([   66,    81,  1317,   423,   654,  2730,   842,    56,   473,\n",
            "          13,     7,  5406,  1806,  5858,    15,  1317,   824,  5858,\n",
            "          35,   438,  2388,     7, 13146,  1722,    15,  1317,  1933,\n",
            "         824,   325,  2302,   908,     7,  1484,     8, 17526,    41,\n",
            "          27,   349,    13,     7,  5138,    35,  1983,  1084,   873,\n",
            "        1722,    47,    27,    44,  1529,  2094,    35,  2615, 13119,\n",
            "          36,  1209,  3918,     7,  2977,    57,    16,     8, 12821,\n",
            "         824,  5858,    35, 14797,  6876,   325, 18377,  5858,   101,\n",
            "        1806,  5858,    32,    63,  5445,    13,     7,  2189,    35,\n",
            "        3082,    28,  2730,    35,   730,   325, 17526,   908,     7,\n",
            "        2977,    57,    13,     7, 17526,    15,    27,   785,    34,\n",
            "          58,    25,  1722,    37,    27,   572,   251,  1690,   158,\n",
            "         154,   337,   141,     7,  5138,    35, 19639,  1084,  1141,\n",
            "        8019,  1722,   187,  2147,   778,    47,  8019,   141,   660,\n",
            "        3918,     7,  2977,     7,  1484,     8, 17526,    41,    27,\n",
            "         349,    13,     7,  5138,    35, 19639,  1084,   873,   385,\n",
            "         619,    97,  1535,    25,  1722,  2814,    37,    89,  3745,\n",
            "        1195,   141,    47,    97,    22,     7,  2085,    22,  7155,\n",
            "          35, 29548,  3563,    25,  1262,  1413,    35,  3918,     7,\n",
            "        2930,   705,  2343,   824,  2388,     7,  2977,    57,    13,\n",
            "           7,   196, 27311,  5638,    15,   400,   785,     7,  1484,\n",
            "           8, 12821,   824,   704,   957,    35,  9649,   957,  5799,\n",
            "          13,     7,  9649,    13,     7,  3616,  2730,   325, 17526,\n",
            "         908,     7,  1102,  5674,   584, 14546,  5638,    15,  2528,\n",
            "          28,  2715,   438,  6939,  1312,   584, 14546,  5638,  2388,\n",
            "           7,  2977,   333,    13,     7, 12821,   824,   704,   957,\n",
            "          35, 27844,  2388,     7,  2977,     7,  2977,    57,    13,\n",
            "           7,  5138,    35, 19639,  1084,  1210,  4118,   228,   594,\n",
            "         101,  4768,   163,   228,  2730,   491,    54,  1317,   423,\n",
            "         654,  2730,  3918,     7,  2977,     7,  8428,  5004,    47,\n",
            "          49,  2166,    71,   397,    54,  1925,    44,  1529,  2094,\n",
            "           7,  1484,     8,  1652,  1102,  5674,   584, 14546,  5638,\n",
            "          35,  7358,   325, 17526,    35,   438, 17109,  5638, 28609,\n",
            "          13,     7, 17526,  8570,   839,  7329,   785,     7,  2930,\n",
            "       27311,   423,   662,  6658,   325, 17526,   101, 27311,  5638,\n",
            "         908,     7,  2029, 22479,    18,   421,  1678,  1047,     7,\n",
            "        2977,     7,  2977,     7,  2930,  1722,    53,    27,   785,\n",
            "           7,  2977,    19,    28,  8100,  1047,    66,    81,  1317,\n",
            "         824,   842,    13,     7,  9485,  1548,   785,     7, 25159,\n",
            "        7483,    15,  1317,   824,  2056,    35,  2071,  2388,     7,\n",
            "        9649,    13,     7,  8428,   280,    25,  1722,    47,  3458,\n",
            "         144,    16,   141,    47,    25,   268,   367,   101,    31,\n",
            "         209,  9712,     7,  1484,     8,  2467,   175,    35, 14225,\n",
            "        7342,  2730,   287,  1933,  9574,   842,     7, 24587,     8,\n",
            "         438, 13146,   842,    41,    27,   349,     7, 24587,     8,\n",
            "         438, 13146,  2715,   438,  5860, 13146,  2715,  1510,   842,\n",
            "          41,    43,  5445,    13,     7,  5138,    35,  2474,  1084,\n",
            "        7342,  1722,   277,    45,   697,   101, 14807,    35, 14225,\n",
            "        7342,  2730,   287,  1933,  9574,  3731,     7,  5138,    35,\n",
            "        2474,  1084,   881,    47,    27,    45,   697,   101,  2528,\n",
            "          28,   842,    41,    27,   908,     7,  5138,    35,  2474,\n",
            "        1084,  5860,  1361,    28,   103,    47,  1861,    45,   697,\n",
            "         101,  2528,    28,  2715,   438,  5860, 13146,  2715, 20477,\n",
            "        3731,     7, 12236,    15,   705,  2343,   824,  2388,     7,\n",
            "        2977,    57,    13,     7, 12236,    15,  1317,   423,   654,\n",
            "        2730,  2388,     7,  2977,     7,  1316,  2794,  2010,  2388,\n",
            "           7,  2977,    83,     8,  4532,    52,   349,    13,     7,\n",
            "        5138,    35,  1983,  1084,   740,    37,  1317,  1413,  1209,\n",
            "         107,    25,  1007,  1413,   697,   101,    36,    35,  9910,\n",
            "        1769,   801,   101,    52,   908,     7,  2930,    91,   785,\n",
            "           7,  2977,   333,    13,     7,  1484,     8,  9271,   334,\n",
            "          53,    27,   349,    13,     7,  9271,   334,    35,  6022,\n",
            "        2388,     7,  2977,     7,  2977,     7,  1484,     8, 12236,\n",
            "         349,    13,     7,  1635,   541,  1445,  7651,  1933,  3856,\n",
            "          15,   210,    35,   584,  1632,  2388,     7,  2977,     7,\n",
            "        2930,  1548,   785,     7,  2977,     1], dtype=int32), 'targets_pretokenized': b'} else {<nl>deltaSuccesses++;', 'targets': array([   14,    57,    13,     7, 17526,  2531,   839,  7329,   785,\n",
            "           1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'private LocalDateArbitrary setDateParams(LocalDateArbitrary dates) {<nl><extra_id_0><nl>if (dayOfMonthBetween.getMin() != null && dayOfMonthBetween.getMax() != null) {<nl>dates = dates.dayOfMonthBetween(dayOfMonthBetween.getMin(), dayOfMonthBetween.getMax());<nl>}<nl>dates = dates.onlyDaysOfWeek(allowedDayOfWeeks.get().toArray(new DayOfWeek[]{}));<nl>return dates;<nl>} <sep> @Override<nl>public BinRange[] getNormalizedRanges(final NumericData range) {<nl>if ((range == null) || (range.getMax() < range.getMin())) {<nl>return new BinRange[] {};<nl>}<nl>return getNormalizedRanges(range.getMin().longValue(), range.getMax().longValue());<nl>}', 'inputs': array([   66,  4116,   383,   334,  4122,   334,  3980, 10042,   607,\n",
            "         325, 20930,   383,   334,  4122,   334,  3980,  8945,   349,\n",
            "          13,     7,  2029, 22479,    18,   421,  1678,  1047,     7,\n",
            "        1484,     8,  6649, 20717,  5128,    35,   438,  2036,   842,\n",
            "          53,    27,    80, 10971,  5128,    35,   438,  1259,   842,\n",
            "          53,    27,   349,    13,     7,  3245,    28,    15,  8945,\n",
            "          35,  6649, 20717,  5128,   325,  6649, 20717,  5128,    35,\n",
            "         438,  2036,  5555, 10971,  5128,    35,   438,  1259,  3731,\n",
            "           7,  2977,     7,  3245,    28,    15,  8945,    35,  4698,\n",
            "        4378,   541,  6306,   325, 22738,  8656,    28,    35,   438,\n",
            "        2715,  1205,   373,   325,  2401,    24,  8656,  5035,  7858,\n",
            "        4684,     7,  2930,  8945,   785,     7,  2977,    19,    28,\n",
            "        8100,  1047,    20,  2913,     7,  4943,    24,  6010,   718,\n",
            "        5035,    31,  7114,  4851,   325,  9366,  9149,   139,   695,\n",
            "         349,    13,     7,  1484,     8,   325,  5258,    41,    27,\n",
            "         349,   118,     8,  5258,    35,   438,  1259,   842,    19,\n",
            "         695,    35,   438,  2036, 28609,    13,     7,  2930,    23,\n",
            "          24,  6010,   718,  5035,   918,   785,     7,  2977,     7,\n",
            "        2930,    31,  7114,  4851,   325,  5258,    35,   438,  2036,\n",
            "        2715,  5406,   120,  5555,   695,    35,   438,  1259,  2715,\n",
            "        5406,   120,  3731,     7,  2977,     1], dtype=int32), 'targets_pretokenized': b'dates = dates.onlyMonths(allowedMonths.get().toArray(new Month[]{}));', 'targets': array([ 8945,    15,  8945,    35,  4698, 11969,   325, 22738, 11969,\n",
            "          35,   438,  2715,  1205,   373,   325,  2401, 17916,  5035,\n",
            "        7858,  4684,     1], dtype=int32)}\n"
          ]
        }
      ],
      "source": [
        "finetuning_task = t5.data.TaskRegistry.get(TASK_NAME)\n",
        "ds = finetuning_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 1024, \"targets\": 1024})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQobwjpVCJbu"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcNX1djT-ugc"
      },
      "outputs": [],
      "source": [
        "from t5 import models\n",
        "\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "tf.app.flags.DEFINE_string ('f', '', 'kernel')\n",
        "\n",
        "#See https://github.com/google-research/text-to-text-transfer-transformer if you want to scale up the model\n",
        "MODEL_SIZE = \"base\"  \n",
        "\n",
        "MODEL_DIR = 'gs://bucket_context/eighth_experiment/ft_final_model_{}'.format(config)\n",
        "\n",
        "PRETRAINED_DIR='gs://bucket_context/eighth_experiment/pt_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 64, 50),\n",
        "    \"base\": (2, 32, 100),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 1024, \"targets\": 1024},\n",
        "    learning_rate_schedule = 0.001,\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgwnN7u1BDu4",
        "outputId": "73c18548-a507-4a6a-e7fd-ddca1ad244bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_config/operative_config_constant.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_config/operative_config_constant.gin\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:absl:Using an uncached FunctionDataset for training is not recommended since it often results in insufficient shuffling on restarts, resulting in overfitting. It is highly recommended that you cache this task before training with it or use a data source that supports lower-level shuffling (e.g., FileDataSource).\n",
            "From /usr/local/lib/python3.8/dist-packages/seqio/dataset_providers.py:1537: sample_from_datasets_v2 (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.sample_from_datasets(...)`.\n",
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py:1175: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "From /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:758: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ]
        }
      ],
      "source": [
        "PATH_GIN_FILE = 'operative_config_constant.gin file'\n",
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 160000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"task\",\n",
        "        pretrained_model_dir=MODEL_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_Qs1dzBV9h5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}