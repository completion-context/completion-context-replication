{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGdy4uJq1kSQ"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HNJ04EH1qdW"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output \n",
        "!pip install tensorflow==2.9 t5 tensorflow-text==2.9\n",
        "#!pip install -q t5 tensorflow-text==2.4.3\n",
        "#!pip install -q tensorflow-text==2.8.0rc0\n",
        "#!pip install -U tensorflow-gcs-config==2.9.1\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g65Qu6MF1x2W",
        "outputId": "453e721c-6ae0-41d9-97d0-d89d35bf5e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "import functools\n",
        "import os\n",
        "import gin\n",
        "import tensorflow_gcs_config\n",
        "from google.colab import auth\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "import t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1MRzBLtex2",
        "outputId": "3dfe83f4-0924-4b93-c077-81d5e7ec6cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up GCS access...\n",
            "WARNING: auth.authenticate_user() will eventually stop supporting auth for Tensorflow on TPU devices. See auth.authenticate_service_account() instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU: grpc://10.70.238.138:8470\n"
          ]
        }
      ],
      "source": [
        "TOKENIZER_DIR = \"bucket path\" #@param { type: \"string\" }\n",
        "if not TOKENIZER_DIR or TOKENIZER_DIR == \"gs://\": \n",
        "  raise ValueError(\"You must enter a TOKENIZER_DIR.\")\n",
        "\n",
        "print(\"Setting up GCS access...\")\n",
        "os.environ['USE_AUTH_EPHEM'] = '0'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set credentials for GCS reading/writing from Colab and TPU.\n",
        "TPU_TOPOLOGY = \"2x2\"\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  TPU_ADDRESS = tpu.get_master()\n",
        "  print('Running on TPU:', TPU_ADDRESS)\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "\n",
        "#LOGGING\n",
        "tf.get_logger().propagate = False\n",
        "py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0kxnD0T8EzI"
      },
      "source": [
        "# Load Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5h4PkSo_Kus",
        "outputId": "6f7caadf-47ac-4e63-fae1-f5aca67dccb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://bucket_context/eighth_experiment/code.model\n",
            "gs://bucket_context/eighth_experiment/code.vocab\n"
          ]
        }
      ],
      "source": [
        "vocab_model_path = 'gs://bucket_context/eighth_experiment/code.model'\n",
        "vocab_path = 'gs://bucket_context/eighth_experiment/code.vocab'\n",
        "print(vocab_model_path)\n",
        "print(vocab_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wq4YkN9_UkO"
      },
      "outputs": [],
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "num_special_mask_tokens = 100 #@param {type: \"integer\"}\n",
        "\n",
        "def load_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, num_special_mask_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change config file based on the finetuning context you want to perform\n",
        "config=\"call\""
      ],
      "metadata": {
        "id": "AzX8GZjGVVne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3yMW-___hYd"
      },
      "source": [
        "# Prepare Dataset for T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "outputs": [],
      "source": [
        "# save each dataset in a folder named ft_ followed by the current context\n",
        "train_path = 'gs://bucket_context/eighth_experiment/ft_{}/train.tsv'.format(config) #@param { type: \"string\" }\n",
        "eval_path = 'gs://bucket_context/eighth_experiment/ft_{}/eval.tsv'.format(config) #@param { type: \"string\" }\n",
        "test_path = 'gs://bucket_context/eighth_experiment/ft_{}/test.tsv'.format(config) #@param { type: \"string\" }\n",
        "finetune_datasets_paths = {\n",
        "    \"train\":      train_path,\n",
        "    \"validation\": eval_path\n",
        "}\n",
        "\n",
        "# Useful when multi-task training \n",
        "# num_input_examples = dict(train=106382, validation=12020) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0NTLbyXvkCs"
      },
      "outputs": [],
      "source": [
        "def load_dataset(split, shuffle_files=True):\n",
        "  \"\"\"\n",
        "  Function to load .tsv dataset as a tf.data.Dataset in TensorFlow\n",
        "  \"\"\"\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(finetune_datasets_paths[split])\n",
        "  ds = ds.map(functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                          field_delim=\"\\t\", use_quote_delim=False)\n",
        "                          , \n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J4_UFsVmSPk"
      },
      "source": [
        "### A few examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__RNWuimAxS9",
        "outputId": "bf02f3f1-5084-4cf3-f709-0c10f91f4b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'@Override<nl><extra_id_0><nl>if (!softLimitsEnabled) {<nl>return;<nl>}<nl>double xOffset = workCoord.x - machineCoord.x;<nl>double yOffset = workCoord.y - machineCoord.y;<nl>double zOffset = workCoord.z - machineCoord.z;<nl>Position bottomLeft = new Position(-maxPosition.getX() + xOffset, -maxPosition.getY() + yOffset, -maxPosition.getZ() + zOffset);<nl>Position topRight = new Position(xOffset, yOffset, zOffset);<nl>GL2 gl = drawable.getGL().getGL2();<nl>gl.glPushMatrix();<nl>drawBase(gl, bottomLeft, topRight);<nl>drawSides(gl, bottomLeft, topRight);<nl>drawAxisLines(gl, bottomLeft, topRight);<nl>gl.glPopMatrix();<nl>} <sep> @Override<nl>public void draw(GLAutoDrawable drawable, boolean idle, Position machineCoord, Position workCoord, Position focusMin, Position focusMax, double scaleFactor, Position mouseCoordinates, Position rotation) {<nl>if (points.isEmpty() && startLine > 0 && endLine > 0) {<nl>return;<nl>}<nl>if (this.scaleFactor != scaleFactor) {<nl>this.scaleFactor = scaleFactor;<nl>generateBufferedLines();<nl>}<nl>float[] c = VisualizerOptions.colorToFloatArray(highlightColor);<nl>GL2 gl = drawable.getGL().getGL2();<nl>gl.glBegin(GL2ES3.GL_QUADS);<nl>gl.glColor4fv(c, 0);<nl>points.forEach(point -> gl.glVertex3d(point.x, point.y, point.z));<nl>gl.glEnd();<nl>}', 'output': b'public void draw(GLAutoDrawable drawable, boolean idle, Position machineCoord, Position workCoord, Position focusMin, Position focusMax, double scaleFactor, Position mouseWorldCoordinates, Position rotation) {'}\n",
            "{'input': b'@Override<nl>public void draw(GLAutoDrawable drawable, boolean idle, Position machineCoord, Position workCoord, Position focusMin, Position focusMax, double scaleFactor, Position mouseWorldCoordinates, Position rotation) {<nl>if (!softLimitsEnabled) {<nl>return;<nl>}<nl>double xOffset = workCoord.x - machineCoord.x;<nl>double yOffset = workCoord.y - machineCoord.y;<nl>double zOffset = workCoord.z - machineCoord.z;<nl><extra_id_0><nl>GL2 gl = drawable.getGL().getGL2();<nl>gl.glPushMatrix();<nl>drawBase(gl, bottomLeft, topRight);<nl>drawSides(gl, bottomLeft, topRight);<nl>drawAxisLines(gl, bottomLeft, topRight);<nl>gl.glPopMatrix();<nl>} <sep> @Override<nl>public void draw(GLAutoDrawable drawable, boolean idle, Position machineCoord, Position workCoord, Position focusMin, Position focusMax, double scaleFactor, Position mouseCoordinates, Position rotation) {<nl>if (points.isEmpty() && startLine > 0 && endLine > 0) {<nl>return;<nl>}<nl>if (this.scaleFactor != scaleFactor) {<nl>this.scaleFactor = scaleFactor;<nl>generateBufferedLines();<nl>}<nl>float[] c = VisualizerOptions.colorToFloatArray(highlightColor);<nl>GL2 gl = drawable.getGL().getGL2();<nl>gl.glBegin(GL2ES3.GL_QUADS);<nl>gl.glColor4fv(c, 0);<nl>points.forEach(point -> gl.glVertex3d(point.x, point.y, point.z));<nl>gl.glEnd();<nl>}', 'output': b'Position bottomLeft = new Position(-maxPosition.getX() + xOffset, -maxPosition.getY() + yOffset, -maxPosition.getZ() + zOffset);<nl>Position topRight = new Position(xOffset, yOffset, zOffset);'}\n",
            "{'input': b'<extra_id_0><nl>private CompletableFuture<PublishAck> publishAsyncInternal(String subject, Headers headers, byte[] data, boolean utf8mode, PublishOptions options, Duration knownTimeout) {<nl>Headers merged = mergePublishOptions(headers, options);<nl>if (jso.isPublishNoAck()) {<nl>conn.publishInternal(subject, null, merged, data, utf8mode);<nl>return null;<nl>}<nl>CompletableFuture<Message> future = conn.requestFutureInternal(subject, merged, data, utf8mode, knownTimeout, false);<nl>return future.thenCompose(resp -> {<nl>try {<nl>responseRequired(resp);<nl>return CompletableFuture.completedFuture(processPublishResponse(resp, options));<nl>} catch (IOException | JetStreamApiException e) {<nl>throw new RuntimeException(e);<nl>}<nl>});<nl>} <sep> @Deprecated // Plans are to remove allowing utf8mode<nl>private PublishAck publishSyncInternal(String subject, Headers headers, byte[] data, boolean utf8mode, PublishOptions options) throws IOException, JetStreamApiException {<nl>Headers merged = mergePublishOptions(headers, options);<nl>if (jso.isPublishNoAck()) {<nl>conn.publishInternal(subject, null, merged, data, utf8mode);<nl>return null;<nl>}<nl>Duration timeout = options == null ? jso.getRequestTimeout() : options.getStreamTimeout();<nl>Message resp = makeInternalRequestResponseRequired(subject, merged, data, utf8mode, timeout, false);<nl>return processPublishResponse(resp, options);<nl>}', 'output': b'@Deprecated'}\n",
            "{'input': b'private void writeClientFactory(Element e, String packageName, String simpleName) {<nl>final String factoryName = simpleName + \"Factory\";<nl>final String factoryPackageName = packageName.replace(KUBERNETES_APIS_PACKAGE, MICRONAUT_APIS_PACKAGE);<nl>final TypeSpec.Builder builder = TypeSpec.classBuilder(factoryName);<nl>builder.addAnnotation(Factory.class);<nl>final MethodSpec.Builder buildMethod = MethodSpec.methodBuilder(\"build\");<nl>buildMethod.returns(ClassName.get(packageName, simpleName))<nl>.addParameter(ClassName.get(\"io.kubernetes.client.openapi\", \"ApiClient\"), \"apiClient\")<nl>.addAnnotation(Singleton.class)<nl>.addModifiers(Modifier.PROTECTED)<nl>.addCode(\"return new \" + simpleName + \"(apiClient);\");<nl>builder.addMethod(buildMethod.build());<nl><extra_id_0><nl>buildMethod.addAnnotation(BootstrapContextCompatible.class);<nl>}<nl>final JavaFile javaFile = JavaFile.builder(factoryPackageName, builder.build()).build();<nl>try {<nl>final JavaFileObject javaFileObject = filer.createSourceFile(factoryPackageName + \".\" + factoryName, e);<nl>try (Writer writer = javaFileObject.openWriter()) {<nl>javaFile.writeTo(writer);<nl>}<nl>} catch (IOException ioException) {<nl>messager.printMessage(Diagnostic.Kind.ERROR, \"Error occurred generating Kubernetes \" + simpleName + \" factory: \" + ioException.getMessage(), e);<nl>}<nl>} <sep> private void generateGetRenderFunction(ComponentExposedTypeGenerator exposedTypeGenerator,<nl>VueTemplateCompilerResult result,<nl>TemplateParserResult templateParserResult) {<nl>MethodSpec.Builder getRenderFunctionBuilder = MethodSpec<nl>.methodBuilder(\"getRenderFunction\")<nl>.addModifiers(Modifier.PRIVATE)<nl>.returns(Function.class)<nl>.addStatement(\"String renderFunctionString = $S\", result.getRenderFunction());<nl>for (VariableInfo markedDataField : templateParserResult.getMarkedDataFields()) {<nl>String placeHolderDataFieldValue = markedDataFieldToPlaceHolderField(markedDataField.getName());<nl>String fieldName = markedDataField.getName();<nl>if (markedDataField instanceof ComputedVariableInfo)<nl>fieldName = ((ComputedVariableInfo) markedDataField).getFieldName();<nl>getRenderFunctionBuilder<nl>.addStatement(<nl>\"renderFunctionString = $T.replaceVariableInRenderFunction(renderFunctionString, $S, this, () -> this.$L = $L)\",<nl>VueGWTTools.class,<nl>placeHolderDataFieldValue,<nl>fieldName,<nl>getFieldMarkingValueForType(markedDataField.getType())<nl>);<nl>}<nl>getRenderFunctionBuilder<nl>.addStatement(\"return new $T(renderFunctionString)\", Function.class);<nl>exposedTypeGenerator.getClassBuilder().addMethod(getRenderFunctionBuilder.build());<nl>}', 'output': b'if (Objects.equals(simpleName, \"CoreV1Api\")) {<nl>builder.addAnnotation(BootstrapContextCompatible.class);'}\n",
            "{'input': b'private void writeClientFactory(Element e, String packageName, String simpleName) {<nl>final String factoryName = simpleName + \"Factory\";<nl>final String factoryPackageName = packageName.replace(KUBERNETES_APIS_PACKAGE, MICRONAUT_APIS_PACKAGE);<nl>final TypeSpec.Builder builder = TypeSpec.classBuilder(factoryName);<nl>builder.addAnnotation(Factory.class);<nl>final MethodSpec.Builder buildMethod = MethodSpec.methodBuilder(\"build\");<nl>buildMethod.returns(ClassName.get(packageName, simpleName))<nl>.addParameter(ClassName.get(\"io.kubernetes.client.openapi\", \"ApiClient\"), \"apiClient\")<nl>.addAnnotation(Singleton.class)<nl>.addModifiers(Modifier.PROTECTED)<nl>.addCode(\"return new \" + simpleName + \"(apiClient);\");<nl>builder.addMethod(buildMethod.build());<nl>if (Objects.equals(simpleName, \"CoreV1Api\")) {<nl>builder.addAnnotation(BootstrapContextCompatible.class);<nl><extra_id_0><nl>final JavaFile javaFile = JavaFile.builder(factoryPackageName, builder.build()).build();<nl>try {<nl>final JavaFileObject javaFileObject = filer.createSourceFile(factoryPackageName + \".\" + factoryName, e);<nl>try (Writer writer = javaFileObject.openWriter()) {<nl>javaFile.writeTo(writer);<nl>}<nl>} catch (IOException ioException) {<nl>messager.printMessage(Diagnostic.Kind.ERROR, \"Error occurred generating Kubernetes \" + simpleName + \" factory: \" + ioException.getMessage(), e);<nl>}<nl>} <sep> private void generateGetRenderFunction(ComponentExposedTypeGenerator exposedTypeGenerator,<nl>VueTemplateCompilerResult result,<nl>TemplateParserResult templateParserResult) {<nl>MethodSpec.Builder getRenderFunctionBuilder = MethodSpec<nl>.methodBuilder(\"getRenderFunction\")<nl>.addModifiers(Modifier.PRIVATE)<nl>.returns(Function.class)<nl>.addStatement(\"String renderFunctionString = $S\", result.getRenderFunction());<nl>for (VariableInfo markedDataField : templateParserResult.getMarkedDataFields()) {<nl>String placeHolderDataFieldValue = markedDataFieldToPlaceHolderField(markedDataField.getName());<nl>String fieldName = markedDataField.getName();<nl>if (markedDataField instanceof ComputedVariableInfo)<nl>fieldName = ((ComputedVariableInfo) markedDataField).getFieldName();<nl>getRenderFunctionBuilder<nl>.addStatement(<nl>\"renderFunctionString = $T.replaceVariableInRenderFunction(renderFunctionString, $S, this, () -> this.$L = $L)\",<nl>VueGWTTools.class,<nl>placeHolderDataFieldValue,<nl>fieldName,<nl>getFieldMarkingValueForType(markedDataField.getType())<nl>);<nl>}<nl>getRenderFunctionBuilder<nl>.addStatement(\"return new $T(renderFunctionString)\", Function.class);<nl>exposedTypeGenerator.getClassBuilder().addMethod(getRenderFunctionBuilder.build());<nl>}', 'output': b'buildMethod.addAnnotation(BootstrapContextCompatible.class);<nl>}'}\n"
          ]
        }
      ],
      "source": [
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(load_dataset(\"validation\").take(5)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsbHi89ZA5-j"
      },
      "source": [
        "# Dataset Prepocessing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bJZPQgjxKZ1"
      },
      "outputs": [],
      "source": [
        "from tensorflow_datasets.core.utils.type_utils import Shape\n",
        "\n",
        "def preprocessing(ds):\n",
        "  \"\"\"\n",
        "  Preprocess function to convert the tf.data.Dataset into a text-to-text format,\n",
        "  with both inputs and targets fields.\n",
        "  Param: tf.data.Dataset\n",
        "  Return: text-to-text format\n",
        "  \"\"\"\n",
        "  prefix = '' # no prefix for pretraining\n",
        "  def to_inputs_and_targets(ex):\n",
        "    x_input = tf.strings.strip(prefix + ex['input'])\n",
        "    y_label = tf.strings.strip(ex['output']) \n",
        "    inputs = tf.strings.join([x_input], separator=' ')\n",
        "    class_label = tf.strings.join([y_label], separator=' ')\n",
        "    return {'inputs': inputs, 'targets': class_label}\n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vymEYLbQCBRY"
      },
      "source": [
        "### A few examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOyas1ZqBVgE",
        "outputId": "7a2d334b-cc3c-41d0-df4a-b6048955c09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed train examples...\n",
            "{'inputs': b'<extra_id_0><nl>return MapHandlerRegistration.addHandler(this, MapEventType.SHADOW_CHANGED, handler,<nl>new ShadowChangeEventFormatter());<nl>} <sep> public final HandlerRegistration addAnimationChangeHandler(AnimationChangeMapHandler handler) {<nl>return MapHandlerRegistration.addHandler(this, MapEventType.ANIMATION_CHANGED, handler,<nl>new AnimationChangeEventFormatter());<nl>}', 'targets': b'public final HandlerRegistration addShadowChangeHandler(ShadowChangeMapHandler handler) {'}\n",
            "{'inputs': b'public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateVolumeGroupBackupRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(<nl>request.getVolumeGroupBackupId(), \"volumeGroupBackupId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateVolumeGroupBackupDetails(),<nl>\"updateVolumeGroupBackupDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"volumeGroupBackups\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getVolumeGroupBackupId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl><extra_id_0><nl>}<nl>return ib;<nl>} <sep> public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.DeleteInternetGatewayRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(request.getIgId(), \"igId must not be blank\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"internetGateways\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getIgId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl>}<nl>return ib;<nl>}', 'targets': b'if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);'}\n",
            "{'inputs': b'public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateVolumeGroupBackupRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(<nl>request.getVolumeGroupBackupId(), \"volumeGroupBackupId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateVolumeGroupBackupDetails(),<nl>\"updateVolumeGroupBackupDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"volumeGroupBackups\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getVolumeGroupBackupId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl><extra_id_0><nl>return ib;<nl>} <sep> public static com.oracle.bmc.http.internal.WrappedInvocationBuilder fromRequest(<nl>com.oracle.bmc.http.internal.RestClient client,<nl>com.oracle.bmc.core.requests.UpdateDrgAttachmentRequest request) {<nl>Validate.notNull(request, \"request instance is required\");<nl>Validate.notBlank(request.getDrgAttachmentId(), \"drgAttachmentId must not be blank\");<nl>Validate.notNull(<nl>request.getUpdateDrgAttachmentDetails(), \"updateDrgAttachmentDetails is required\");<nl>com.oracle.bmc.http.internal.WrappedWebTarget target =<nl>client.getBaseTarget()<nl>.path(\"/20160918\")<nl>.path(\"drgAttachments\")<nl>.path(<nl>com.oracle.bmc.util.internal.HttpUtils.encodePathSegment(<nl>request.getDrgAttachmentId()));<nl>com.oracle.bmc.http.internal.WrappedInvocationBuilder ib = target.request();<nl>ib.accept(javax.ws.rs.core.MediaType.APPLICATION_JSON);<nl>if (request.getIfMatch() != null) {<nl>ib.header(\"if-match\", request.getIfMatch());<nl>}<nl>if (client.getClientConfigurator() != null) {<nl>client.getClientConfigurator().customizeRequest(request, ib);<nl>}<nl>return ib;<nl>}', 'targets': b'}'}\n",
            "{'inputs': b'<extra_id_0><nl>public OptionalInt findSingle() {<nl>if (iterator.hasNext()) {<nl>int singleCandidate = iterator.nextInt();<nl>if (iterator.hasNext()) {<nl>throw new IllegalStateException(\"IntStream contains more than one element\");<nl>} else {<nl>return OptionalInt.of(singleCandidate);<nl>}<nl>} else {<nl>return OptionalInt.empty();<nl>}<nl>} <sep> @NotNull<nl>public Optional<T> findSingle() {<nl>if (iterator.hasNext()) {<nl>T singleCandidate = iterator.next();<nl>if (iterator.hasNext()) {<nl>throw new IllegalStateException(\"Stream contains more than one element\");<nl>} else {<nl>return Optional.of(singleCandidate);<nl>}<nl>} else {<nl>return Optional.empty();<nl>}<nl>}', 'targets': b'@NotNull'}\n",
            "{'inputs': b'public byte[] getData() {<nl>if (packet != null) {<nl>Object dataSerializer = readObject(0, NMSUtils.packetDataSerializerClass);<nl>WrappedPacket byteBufWrapper = new WrappedPacket(new NMSPacket(dataSerializer));<nl>Object byteBuf = byteBufWrapper.readObject(0, NMSUtils.byteBufClass);<nl>return PacketEvents.get().getByteBufUtil().getBytes(byteBuf);<nl><extra_id_0><nl>return data;<nl>}<nl>} <sep> public byte[] getData() {<nl>if (packet != null) {<nl>switch (constructorMode) {<nl>case 0:<nl>return readByteArray(0);<nl>case 1:<nl>case 2:<nl>return PacketEvents.get().getByteBufUtil().getBytes(getBuffer());<nl>default:<nl>return new byte[0];<nl>}<nl>}<nl>return data;<nl>}', 'targets': b'} else {'}\n"
          ]
        }
      ],
      "source": [
        "print(\"A few preprocessed train examples...\")\n",
        "sample = tfds.as_numpy(preprocessing(load_dataset(\"train\").take(5)))\n",
        "for ex in sample:\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OkQeLeh8Rst"
      },
      "source": [
        "# Creating Task and Mixture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PobLvzL18zzR",
        "outputId": "3012060c-1afb-4b89-9ece-b615d6c6c7ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seqio.dataset_providers.Mixture at 0x7fe6cf81ea60>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=load_vocabulary(), add_eos=True, required=False),\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=load_vocabulary(), add_eos=True)\n",
        "    }\n",
        "\n",
        "TASK_NAME = \"ft\" #@param{ type : \"string\"}\n",
        "\n",
        "# TASK\n",
        "t5.data.TaskRegistry.remove(TASK_NAME)\n",
        "t5.data.TaskRegistry.add(\n",
        "    TASK_NAME,\n",
        "    # Function which returns a tf.data.Dataset\n",
        "    dataset_fn=load_dataset,\n",
        "    splits=[\"train\",\"validation\"],\n",
        "    # List of functions that preprocess the input tf.data.Dataset\n",
        "    text_preprocessor=[preprocessing],\n",
        "    # Accuracy is used as evaluation metric\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, helps for mixing and auto-caching\n",
        "    # num_input_examples=num_input_examples,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES\n",
        ")\n",
        "\n",
        "MIXTURE_NAME = \"task\" #@param{ type : \"string\"}\n",
        "\n",
        "# MIXTURE\n",
        "t5.data.MixtureRegistry.remove(MIXTURE_NAME)\n",
        "t5.data.MixtureRegistry.add(\n",
        "    MIXTURE_NAME,\n",
        "    # List of tasks\n",
        "    [TASK_NAME],\n",
        "    default_rate=1.0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwqLrVdGB6yy"
      },
      "source": [
        "### A few examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVHcIrjkA93r",
        "outputId": "6ba8c8a2-f00c-4de6-f782-0e880582bde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Using an uncached FunctionDataset for training is not recommended since it often results in insufficient shuffling on restarts, resulting in overfitting. It is highly recommended that you cache this task before training with it or use a data source that supports lower-level shuffling (e.g., FileDataSource).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'public static synchronized void addRecentFile(File f)<nl>{<nl>recentFiles.remove(f.getAbsolutePath()); // already added on the list<nl>recentFiles.add(0, f.getAbsolutePath());<nl><extra_id_0><nl>DiskWriter.replaceFile(filesName, MiscUtils.listToString(recentFiles), false);<nl>resetRecentFilesMenu();<nl>} <sep> public static String getFilePrefix(File f) {<nl>String fileName = f.getName();<nl>int mid = fileName.indexOf(\".\");<nl>if (mid < 0) {<nl>return fileName;<nl>}<nl>return fileName.substring(0, mid);<nl>}', 'inputs': array([   29,    62,   453,    48,    59, 13067,   183,   325,   183,\n",
            "         296,   349,     7,  4201,     7,  1102, 12753,  1140,    35,\n",
            "        4218,   325,   364,    35,   438, 21292,  3731,    34,   660,\n",
            "        1052,   146,    25,   127,     7,  1102, 12753,  1140,    35,\n",
            "        1751, 21479,   296,    35,   438, 21292,  3731,     7,  2029,\n",
            "       22479,    18,   421,  1678,  1047,     7,  3688,   565,    35,\n",
            "       10264,   183,   325,  7714,    77,   101, 28696,    28,    35,\n",
            "        1416,  2088,   325,  1102, 12753,  1140,  3341,    91,   908,\n",
            "           7, 12029, 13067,  1140,  2508,  2388,     7,  2977,    19,\n",
            "          28,  8100,  1047,    29,    62,    26,  1975,   866,   325,\n",
            "         183,   296,   349,    13,     7,   196,  1129,    15,   296,\n",
            "          35, 10759,  2388,     7,  2775,  4433,    15,  1129,    35,\n",
            "        1644,   541,  1084,    35,  3918,     7,  1484,     8,   761,\n",
            "         421,    19,    43,   349,    13,     7,  2930,  1129,   785,\n",
            "           7,  2977,     7,  2930,  1129,    35, 23898, 21479,  4433,\n",
            "         908,     7,  2977,     1], dtype=int32), 'targets_pretokenized': b'MiscUtils.deduplicateAndTrim(recentFiles, maxRecentFiles);', 'targets': array([28696,    28,    35,  2576, 17683,   423,  9227,   325,  1102,\n",
            "       12753,  1140,   101,   283, 13067,  1140,   908,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'protected void applySort(CriteriaBuilder cb,<nl>CriteriaQuery<T> cq,<nl>Root<T> root,<nl>Map<String, SortMeta> sortBy) {<nl>if (sortBy != null) {<nl>List<Order> orders = null;<nl>for (SortMeta sort : sortBy.values()) {<nl>if (sort.getField() == null || sort.getOrder() == SortOrder.UNSORTED) {<nl>continue;<nl>}<nl><extra_id_0><nl>}<nl>Expression<?> fieldExpression = resolveFieldExpression(cb, cq, root, sort.getField());<nl>orders.add(sort.getOrder() == SortOrder.ASCENDING ? cb.asc(fieldExpression) : cb.desc(fieldExpression));<nl>}<nl>if (orders != null) {<nl>cq.orderBy(orders);<nl>}<nl>}<nl>} <sep> protected void applyFilters(CriteriaBuilder cb,<nl>CriteriaQuery<?> cq,<nl>Root<T> root,<nl>Map<String, FilterMeta> filterBy) {<nl>List<Predicate> predicates = new ArrayList<>();<nl>applyGlobalFilters(filterBy, cb, cq, root, predicates);<nl>if (filterBy != null) {<nl>for (FilterMeta filter : filterBy.values()) {<nl>if (filter.getField() == null || filter.getFilterValue() == null || filter.isGlobalFilter()) {<nl>continue;<nl>}<nl>String filterValue = filter.getFilterValue().toString();<nl>Field filterField = LangUtils.getFieldRecursive(entityClass, filter.getField());<nl>Object convertedFilterValue = convertToType(filterValue, filterField.getType());<nl>Expression fieldExpression = resolveFieldExpression(cb, cq, root, filter.getField());<nl>Predicate predicate = createPredicate(filter, filterField, root, cb, fieldExpression, (Comparable) convertedFilterValue);<nl>predicates.add(predicate);<nl>}<nl>}<nl>if (!predicates.isEmpty()) {<nl>cq.where(<nl>cb.and(predicates.toArray(new Predicate[predicates.size()])));<nl>}<nl>}', 'inputs': array([  132,    48,   508,  3187,   325,  2558,   177,  2317,   101,\n",
            "           7,  2558,   360,  2029,   601,  1047, 18023,   101,     7,\n",
            "         913,  2029,   601,  1047,   411,   101,     7,   136,  2029,\n",
            "         196,   101,  4644,  1245,  1047,  8177,   349,    13,     7,\n",
            "        1484,     8,  6616,   532,    53,    27,   349,    13,     7,\n",
            "         108,  2029,  1020,  1047,  6998,    15,    27,   785,     7,\n",
            "        3470,     8,  3187,  1245,   909,    45,  8177,    35,  4858,\n",
            "        5799,    13,     7,  1484,     8,  6616,    35,   438,   272,\n",
            "         842,    41,    27,   118,   909,    35,   438,  1020,   842,\n",
            "          41, 20453,    35,  4123, 18404,  1135,   349,    13,     7,\n",
            "       19994,   785,     7,  2977,     7,  2029, 22479,    18,   421,\n",
            "        1678,  1047,     7,  2977,     7,   345, 25564,   181,   345,\n",
            "          15,   678,   272,   345,   325, 16809,   101, 18023,   101,\n",
            "         411,   101,   909,    35,   438,   272,  3731,     7,  4347,\n",
            "          28,    35,  1751,   325,  6616,    35,   438,  1020,   842,\n",
            "          41, 20453,    35, 27636, 30330,    65,  2317,    35, 25151,\n",
            "         325,  3004,   345,   349,    45,  2317,    35, 10084,   325,\n",
            "        3004,   345,  4684,     7,  2977,     7,  1484,     8,  4347,\n",
            "          28,    53,    27,   349,    13,     7,   584,  2090,    35,\n",
            "        4347,   532,   325,  4347,    28,   908,     7,  2977,     7,\n",
            "        2977,     7,  2977,    19,    28,  8100,  1047,   132,    48,\n",
            "         508,  2665,   325,  2558,   177,  2317,   101,     7,  2558,\n",
            "         360, 25564, 18023,   101,     7,   913,  2029,   601,  1047,\n",
            "         411,   101,     7,   136,  2029,   196,   101,  1448,  1245,\n",
            "        1047, 21111,   349,    13,     7,   108,  2029,  1515,  1047,\n",
            "        8975,    15,    23,   199, 26121,  2388,     7, 12114,  2532,\n",
            "        2665,   325,  3841,   532,   101,  2317,   101, 18023,   101,\n",
            "         411,   101,  8975,   908,     7,  1484,     8,  3841,   532,\n",
            "          53,    27,   349,    13,     7,  3470,     8,   366,  1245,\n",
            "         281,    45, 21111,    35,  4858,  5799,    13,     7,  1484,\n",
            "           8,  3841,    35,   438,   272,   842,    41,    27,   118,\n",
            "         281,    35,   438,   366,   120,   842,    41,    27,   118,\n",
            "         281,    35,  1022,  2532,   366,  5799,    13,     7, 19994,\n",
            "         785,     7,  2977,     7,   196,   281,   120,    15,   281,\n",
            "          35,   438,   366,   120,  2715,  5302,  2388,     7,   272,\n",
            "         281,   272,    15, 31026,    28,    35,   438,   272,  6491,\n",
            "         325,  5715,   165,   101,   281,    35,   438,   272,  3731,\n",
            "           7,   200,  2293,   366,   120,    15,  2399,    64,   325,\n",
            "        3841,   120,   101,   281,   272,    35,   438,    64,  3731,\n",
            "           7,   345,   181,   345,    15,   678,   272,   345,   325,\n",
            "       16809,   101, 18023,   101,   411,   101,   281,    35,   438,\n",
            "         272,  3731,     7,  1515,  1075,    15,    92,  1515,   325,\n",
            "        3841,   101,   281,   272,   101,   411,   101,  2317,   101,\n",
            "         181,   345,   101,     8, 14078,   349,  2293,   366,   120,\n",
            "         908,     7, 18348,    28,    35,  1751,   325, 18348,   908,\n",
            "           7,  2977,     7,  2977,     7,  1484,     8,  1652, 18348,\n",
            "          28,    35, 20477,  5799,    13,     7,   584,  2090,    35,\n",
            "        8310,   325,     7, 16809,    35,  2873,   325, 18348,    28,\n",
            "          35,  1205,   373,   325,  2401,  1597,  1862, 18348,    28,\n",
            "          35,  1510,   842, 15278,  4684,     7,  2977,     7,  2977,\n",
            "           1], dtype=int32), 'targets_pretokenized': b'if (orders == null) {<nl>orders = new ArrayList<>();', 'targets': array([   16,     8,  4347,    28,    41,    27,   349,    13,     7,\n",
            "        4347,    28,    15,    23,   199, 26121,  2388,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'@Override<nl>public void close() throws IOException {<nl>if (!_closed) {<nl>// should only close if manage the resource<nl>if (_ioContext.isResourceManaged()) {<nl><extra_id_0><nl>if (src instanceof Closeable) {<nl>((Closeable) src).close();<nl>}<nl>}<nl>_closed = true;<nl>}<nl>} <sep> @Override<nl>public void close() throws IOException {<nl>if (streamClosed) {<nl>return;<nl>}<nl>if (decompressedInputStream != null) {<nl>decompressedInputStream.close();<nl>}<nl>this.streamClosed = true;<nl>}', 'inputs': array([   20,  2913,     7,  4943,    48,   300,   842,    56,   105,\n",
            "          13,     7,  1484,     8,  1652,    18, 13141,   349,    13,\n",
            "           7,  8428,   365,   484,   300,    16,  8390,    25,   204,\n",
            "           7,  1484,     8,    18,  1858,   117,    35,  1022,   278,\n",
            "        4035,  5799,    13,     7,  2029, 22479,    18,   421,  1678,\n",
            "        1047,     7,  1484,     8,  4841,   140,  4196,   349,    13,\n",
            "           7, 12253, 15440,   349,   451,  2275,  5461,  2388,     7,\n",
            "        2977,     7,  2977,     7,    18, 13141,    15,    85,   785,\n",
            "           7,  2977,     7,  2977,    19,    28,  8100,  1047,    20,\n",
            "        2913,     7,  4943,    48,   300,   842,    56,   105,    13,\n",
            "           7,  1484,     8,  2444,  3208,   349,    13,     7,  2930,\n",
            "         785,     7,  2977,     7,  1484,     8,  2576, 28323,   814,\n",
            "          53,    27,   349,    13,     7,  2576, 28323,   814,    35,\n",
            "        5461,  2388,     7,  2977,     7,  2189,    35,  2444,  3208,\n",
            "          15,    85,   785,     7,  2977,     1], dtype=int32), 'targets_pretokenized': b'Object src = _ioContext.contentReference().getRawContent();', 'targets': array([  68,  451,   15,   98, 1858,  117,   35, 3322,  560, 2715,  438,\n",
            "       2666,  489, 2388,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public Name relativize(Name origin) {<nl>if (origin == null || !subdomain(origin)) {<nl>return this;<nl>}<nl>Name newname = new Name();<nl>int length = length() - origin.length();<nl>newname.labels = labels - origin.labels;<nl>newname.offsets = offsets;<nl>newname.name = new byte[length];<nl><extra_id_0><nl>return newname;<nl>} <sep> public static Name concatenate(Name prefix, Name suffix) throws NameTooLongException {<nl>if (prefix.isAbsolute()) {<nl>return prefix;<nl>}<nl>Name newname = new Name();<nl>newname.append(prefix.name, 0, prefix.labels);<nl>newname.append(suffix.name, 0, suffix.labels);<nl>return newname;<nl>}', 'inputs': array([   29,  1379, 19971,   325,    77,  2044,   349,    13,     7,\n",
            "        1484,     8, 20783,    41,    27,   118,    84,  3969,  6592,\n",
            "         325, 20783,  5445,    13,     7,  2930,    36,   785,     7,\n",
            "        2977,     7,    77,    23,   437,    15,    23,  1379,  2388,\n",
            "           7,  2775,    82,    15,    82,   842,    87,  2044,    35,\n",
            "        2244,  2388,     7,  2401,   437,    35,  4124,    28,    15,\n",
            "        2500,    87,  2044,    35,  4124,    28,   785,     7,  2401,\n",
            "         437,    35,  3607,    28,    15,  6478,   785,     7,  2401,\n",
            "         437,    35,   437,    15,    23,   145,  1862,  2244, 19043,\n",
            "           7,  2029, 22479,    18,   421,  1678,  1047,     7,  2930,\n",
            "          23,   437,   785,     7,  2977,    19,    28,  8100,  1047,\n",
            "          29,    62,  1379, 17905,   325,    77,   612,   101,  1379,\n",
            "        1995,   349,    56,  1379,  7908,  1323,    42,    13,     7,\n",
            "        1484,     8,  7477,    35,  1022,  7052,  5799,    13,     7,\n",
            "        2930,   612,   785,     7,  2977,     7,    77,    23,   437,\n",
            "          15,    23,  1379,  2388,     7,  2401,   437,    35,  6544,\n",
            "         325,  7477,    35,   437,   101, 14289,   612,    35,  4124,\n",
            "          28,   908,     7,  2401,   437,    35,  6544,   325, 19505,\n",
            "          35,   437,   101, 14289,  1995,    35,  4124,    28,   908,\n",
            "           7,  2930,    23,   437,   785,     7,  2977,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'System.arraycopy(name, 0, newname.name, 0, length);', 'targets': array([  210,    35,  3687,  7701,   325,   437,   101, 14289,    23,\n",
            "         437,    35,   437,   101, 14289,    82,   908,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'public void startPilgrimage(Monk monk, DiceMonasteryGameState state) {<nl>pilgrimId = monk.getComponentID();<nl>player = monk.getOwnerId();<nl>state.addResource(player, SHILLINGS, -cost);<nl>state.moveMonk(pilgrimId, GATEHOUSE, PILGRIMAGE);<nl>progress = 0;<nl><extra_id_0><nl>active = true;<nl>} <sep> @Override<nl>public boolean _execute(DiceMonasteryGameState state) {<nl>int player = state.getCurrentPlayer();<nl>state.acquireTreasure(treasure, player);<nl>state.addResource(player, DiceMonasteryConstants.Resource.SHILLINGS, -treasure.cost);<nl>return true;<nl>}', 'inputs': array([   29,    48,   155,   674,  4376,  9499,  4082,   325, 16258,\n",
            "        1147,  8708, 15587,   101,   758,  8091, 16258, 25710,   671,\n",
            "       13681,   214,   224,   349,    13,     7,   481,  4376,  9499,\n",
            "        3166,    93,    15,  8708, 15587,    35,   438,   534,   241,\n",
            "        2388,     7, 19145,   315,    15,  8708, 15587,    35,   438,\n",
            "       23589,  2388,     7,  3018,    35,  1751,   278,   325, 19145,\n",
            "         315,   101,    24,  6563, 15827,  1522,   203,   101,    87,\n",
            "        3621,  2074,   908,     7,  3018,    35, 14485, 16258,  1147,\n",
            "         325,   481,  4376,  9499,  3166,    93,   101,  1224, 11062,\n",
            "         910,   993,  8803,   101,  6183,   485, 15622,  8610,   908,\n",
            "           7, 11646,    15, 11381,     7,  2029, 22479,    18,   421,\n",
            "        1678,  1047,     7,  5902,    15,    85,   785,     7,  2977,\n",
            "          19,    28,  8100,  1047,    20,  2913,     7,  4943,    81,\n",
            "          98,  9787,   325,   285,  8091, 16258, 25710,   671, 13681,\n",
            "         214,   224,   349,    13,     7,  2775,  5530,    15,   224,\n",
            "          35, 27108,  6285,  2388,     7,  3018,    35,  3478, 18187,\n",
            "         601,  1102,  2833,  7096,   325,  2857,  7394,    28,  7096,\n",
            "         101,  5530,   908,     7,  3018,    35,  1751,   278,   325,\n",
            "       19145,   315,   101,   758,  8091, 16258, 25710,   671,   655,\n",
            "          35,   278,    35,  6563, 15827,  1522,   203,   101,    87,\n",
            "        2857,  7394,    28,  7096,    35,  3621,  2074,   908,     7,\n",
            "        2930,    85,   785,     7,  2977,     1], dtype=int32), 'targets_pretokenized': b'state.addVP(vpPerStep[0], player);', 'targets': array([  224,    35,  1751,   667,   674,   325, 12618,  2319,  1330,\n",
            "       10851,   101,  5530,   908,     1], dtype=int32)}\n"
          ]
        }
      ],
      "source": [
        "finetuning_task = t5.data.TaskRegistry.get(TASK_NAME)\n",
        "ds = finetuning_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 1024, \"targets\": 1024})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQobwjpVCJbu"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from t5 import models\n",
        "\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "tf.app.flags.DEFINE_string ('f', '', 'kernel')\n",
        "\n",
        "#See https://github.com/google-research/text-to-text-transfer-transformer if you want to scale up the model\n",
        "MODEL_SIZE = \"base\"  \n",
        "\n",
        "MODEL_DIR = 'gs://bucket_context/eighth_experiment/ft_final_model_{}'.format(config)\n",
        "\n",
        "PRETRAINED_DIR='gs://bucket_context/eighth_experiment/pt_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 64, 50),\n",
        "    \"base\": (2, 32, 100),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 1024, \"targets\": 1024},\n",
        "    learning_rate_schedule = 0.001,\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max\n",
        ")"
      ],
      "metadata": {
        "id": "FcNX1djT-ugc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 512\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"task\",\n",
        "    # mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=-1 #evaluate only last checkpoint\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "11qeh_bnEfgr",
        "outputId": "d1106e01-29d3-4d00-e83f-66b9549610ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "INFO:absl:Adding task 'ft' with predict metric_fn(s).\n",
            "INFO:absl:Skipping packing/padding for 'ft' since sequence length is None.\n",
            "INFO:absl:Setting sequence lengths to {'inputs': 1350, 'targets': 299}\n",
            "INFO:absl:Evaluating checkpoint step: 1670000\n",
            "INFO:absl:Padding 'ft' with sequence lengths: {'inputs': 1350, 'targets': 299}\n",
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "From /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:825: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "Closing session due to error Graph execution error:\n",
            "\n",
            "From /job:worker/replica:0/task:0:\n",
            "9 root error(s) found.\n",
            "  (0) RESOURCE_EXHAUSTED: Ran out of memory in memory space hbm. Used 16.22G of 7.48G hbm. Exceeded hbm capacity by 8.74G.\n",
            "\n",
            "Total hbm usage >= 16.74G:\n",
            "    reserved        530.00M \n",
            "    program          16.22G \n",
            "    arguments            0B \n",
            "\n",
            "Output size 0B; shares 0B with arguments.\n",
            "\n",
            "Program hbm requirement 16.22G:\n",
            "    global            7.46M\n",
            "    HLO temp         16.21G (38.1% utilization: Unpadded (6.15G) Padded (16.16G), 0.3% fragmentation (51.47M))\n",
            "\n",
            "  Largest program allocations in hbm:\n",
            "\n",
            "  1. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1380.remat_uncompressed.1.remat_uncompressed = copy(copy.1380.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  2. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: wide_param.139 = parameter(0)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  3. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1381.remat_uncompressed.1.remat_uncompressed = copy(copy.1381.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  4. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1382.remat_uncompressed.1.remat_uncompressed = copy(copy.1382.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  5. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1383.remat_uncompressed.1.remat_uncompressed = copy(copy.1383.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  6. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1384.remat_uncompressed.1.remat_uncompressed = copy(copy.1384.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  7. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1385.remat_uncompressed.1.remat_uncompressed = copy(copy.1385.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  8. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: wide_param.139 = parameter(0)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  9. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: wide_param.139 = parameter(0)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  10. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: wide_param.139 = parameter(0)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  11. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1386.remat_uncompressed.1.remat_uncompressed = copy(copy.1386.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  12. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1387.remat_uncompressed.1.remat_uncompressed = copy(copy.1387.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  13. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1388.remat_uncompressed.1.remat_uncompressed = copy(copy.1388.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  14. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1389.remat_uncompressed.1.remat_uncompressed = copy(copy.1389.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  15. Size: 337.50M\n",
            "     Operator: op_type=\"Sum\" op_name=\"while_loop/while/decoder/block_010/layer_000/SelfAttention/einsum_20/Sum\"\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: fusion.799 = fusion(copy.1245.remat_uncompressed, get-tuple-element.90544, copy.1247, get-tuple-element.92543, ...(+1)), kind=kLoop, calls=fused_computation.691\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  16. Size: 337.50M\n",
            "     Operator: op_type=\"Sum\" op_name=\"while_loop/while/decoder/block_009/layer_000/SelfAttention/einsum_20/Sum\"\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: fusion.803 = fusion(copy.1232.remat_uncompressed, get-tuple-element.90544, copy.1234, get-tuple-element.92541, ...(+1)), kind=kLoop, calls=fused_computation.695\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  17. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1390.remat_uncompressed.1.remat_uncompressed = copy(copy.1390.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  18. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1391.remat_uncompressed.1.remat_uncompressed = copy(copy.1391.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  19. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1392.remat_uncompressed.1.remat_uncompressed = copy(copy.1392.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "  20. Size: 337.50M\n",
            "     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n",
            "     Unpadded size: 126.56M\n",
            "     Extra memory due to padding: 210.94M (2.7x expansion)\n",
            "     XLA label: copy.1393.remat_uncompressed.1.remat_uncompressed = copy(copy.1393.remat_uncompressed.1.remat_compressed)\n",
            "     Allocation type: HLO temp\n",
            "     ==========================\n",
            "\n",
            "\n",
            "\t [[{{node TPUReplicate/_compile/_8390262247316149459/_2}}]]\n",
            "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
            "\n",
            "  (1) RESOURCE_EXHAUSTED: Ran out of memory in memory space hbm. Used 16.22G of 7.48G hbm. Exceeded hbm capacity by 8.74G.\n",
            "\n",
            "Total hbm usage >= 16.74G:\n",
            "    reserved        530.00M \n",
            "    program          16.22G \n",
            "    arguments            0B \n",
            "\n",
            "Output size 0B; shares 0B with arguments.\n",
            "\n",
            "Program hbm requirement 16.22G:\n",
            "    global            7.46M\n",
            "    HLO temp         16.21G (38.1% utilization: Unpadded (6.15G) Padded (16.16G), 0.3% f\n",
            "Reraising captured error\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   3133\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3134\u001b[0;31m       for result in super(TPUEstimator, self).predict(\n\u001b[0m\u001b[1;32m   3135\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    641\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             \u001b[0mpreds_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myield_single_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \"\"\"\n\u001b[0;32m--> 782\u001b[0;31m     return self._sess.run(\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         return self._sess.run(\n\u001b[0m\u001b[1;32m   1312\u001b[0m             \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1468\u001b[0m     \u001b[0mrun_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m     outputs = _WrappedSession.run(\n\u001b[0m\u001b[1;32m   1470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1371\u001b[0m                            run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1361\u001b[0m                                       target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1453\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-701717352854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use a larger batch size for evaluation, which requires less memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.eval(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# mixture_or_task_name=\"all_tasks\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/t5/models/mtf_model.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, mixture_or_task_name, checkpoint_steps, summary_dir, split, eval_with_score, compute_sequence_length)\u001b[0m\n\u001b[1;32m    342\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0meval_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     utils.run_eval(\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         predict_or_score_fn=functools.partial(self._predict_or_score_fn,\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/t5/models/utils.py\u001b[0m in \u001b[0;36mrun_eval\u001b[0;34m(mixture_or_task_name, predict_or_score_fn, checkpoint_steps, dataset_fn, summary_dir, split, sequence_length, batch_size)\u001b[0m\n\u001b[1;32m    332\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating checkpoint step: %d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     outputs = predict_or_score_fn(\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mcheckpoint_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/t5/models/mtf_model.py\u001b[0m in \u001b[0;36m_predict_or_score_fn\u001b[0;34m(self, tasks, vocabulary, checkpoint_step, sequence_length, split, eval_with_score, **unused_kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m           vocabulary)\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m       outputs = [\n\u001b[0m\u001b[1;32m    295\u001b[0m           tf.compat.as_text(d) for d in mtf_utils.decode(\n\u001b[1;32m    296\u001b[0m               estimator, estimator_input_fn, vocabulary, checkpoint_path)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/t5/models/mtf_model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    292\u001b[0m           vocabulary)\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m       outputs = [\n\u001b[0m\u001b[1;32m    295\u001b[0m           tf.compat.as_text(d) for d in mtf_utils.decode(\n\u001b[1;32m    296\u001b[0m               estimator, estimator_input_fn, vocabulary, checkpoint_path)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mesh_tensorflow/transformer/utils.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(estimator, input_fn, vocabulary, checkpoint_path)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     input_string = _maybe_detokenize(\n\u001b[1;32m   1350\u001b[0m         result[\"inputs\"], inputs_vocabulary(vocabulary))\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   3143\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3145\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3147\u001b[0m     \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\u001b[0m in \u001b[0;36mcatch_errors\u001b[0;34m(self, source, session)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"\"\"Context manager to report any errors within a block.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_run_infeed\u001b[0;34m(self, queue_ctx, session)\u001b[0m\n\u001b[1;32m    530\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_iteration_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m           \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enqueue_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Infeed thread finished, shutting down.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1371\u001b[0m                            run_metadata)\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1394\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1396\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nFrom /job:worker/replica:0/task:0:\n9 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: Ran out of memory in memory space hbm. Used 16.22G of 7.48G hbm. Exceeded hbm capacity by 8.74G.\n\nTotal hbm usage >= 16.74G:\n    reserved        530.00M \n    program          16.22G \n    arguments            0B \n\nOutput size 0B; shares 0B with arguments.\n\nProgram hbm requirement 16.22G:\n    global            7.46M\n    HLO temp         16.21G (38.1% utilization: Unpadded (6.15G) Padded (16.16G), 0.3% fragmentation (51.47M))\n\n  Largest program allocations in hbm:\n\n  1. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1380.remat_uncompressed.1.remat_uncompressed = copy(copy.1380.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  2. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: wide_param.139 = parameter(0)\n     Allocation type: HLO temp\n     ==========================\n\n  3. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1381.remat_uncompressed.1.remat_uncompressed = copy(copy.1381.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  4. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1382.remat_uncompressed.1.remat_uncompressed = copy(copy.1382.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  5. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1383.remat_uncompressed.1.remat_uncompressed = copy(copy.1383.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  6. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1384.remat_uncompressed.1.remat_uncompressed = copy(copy.1384.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  7. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1385.remat_uncompressed.1.remat_uncompressed = copy(copy.1385.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  8. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: wide_param.139 = parameter(0)\n     Allocation type: HLO temp\n     ==========================\n\n  9. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: wide_param.139 = parameter(0)\n     Allocation type: HLO temp\n     ==========================\n\n  10. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: wide_param.139 = parameter(0)\n     Allocation type: HLO temp\n     ==========================\n\n  11. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1386.remat_uncompressed.1.remat_uncompressed = copy(copy.1386.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  12. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1387.remat_uncompressed.1.remat_uncompressed = copy(copy.1387.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  13. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1388.remat_uncompressed.1.remat_uncompressed = copy(copy.1388.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  14. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1389.remat_uncompressed.1.remat_uncompressed = copy(copy.1389.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  15. Size: 337.50M\n     Operator: op_type=\"Sum\" op_name=\"while_loop/while/decoder/block_010/layer_000/SelfAttention/einsum_20/Sum\"\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: fusion.799 = fusion(copy.1245.remat_uncompressed, get-tuple-element.90544, copy.1247, get-tuple-element.92543, ...(+1)), kind=kLoop, calls=fused_computation.691\n     Allocation type: HLO temp\n     ==========================\n\n  16. Size: 337.50M\n     Operator: op_type=\"Sum\" op_name=\"while_loop/while/decoder/block_009/layer_000/SelfAttention/einsum_20/Sum\"\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: fusion.803 = fusion(copy.1232.remat_uncompressed, get-tuple-element.90544, copy.1234, get-tuple-element.92541, ...(+1)), kind=kLoop, calls=fused_computation.695\n     Allocation type: HLO temp\n     ==========================\n\n  17. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1390.remat_uncompressed.1.remat_uncompressed = copy(copy.1390.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  18. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1391.remat_uncompressed.1.remat_uncompressed = copy(copy.1391.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  19. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1392.remat_uncompressed.1.remat_uncompressed = copy(copy.1392.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n  20. Size: 337.50M\n     Shape: bf16[128,1350,6,64]{3,2,1,0:T(8,128)(2,1)}\n     Unpadded size: 126.56M\n     Extra memory due to padding: 210.94M (2.7x expansion)\n     XLA label: copy.1393.remat_uncompressed.1.remat_uncompressed = copy(copy.1393.remat_uncompressed.1.remat_compressed)\n     Allocation type: HLO temp\n     ==========================\n\n\n\t [[{{node TPUReplicate/_compile/_8390262247316149459/_2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: Ran out of memory in memory space hbm. Used 16.22G of 7.48G hbm. Exceeded hbm capacity by 8.74G.\n\nTotal hbm usage >= 16.74G:\n    reserved        530.00M \n    program          16.22G \n    arguments            0B \n\nOutput size 0B; shares 0B with arguments.\n\nProgram hbm requirement 16.22G:\n    global            7.46M\n    HLO temp         16.21G (38.1% utilization: Unpadded (6.15G) Padded (16.16G), 0.3% f"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoints to check (300k -> 425k)\n",
        "\n",
        "to_check=list(range(1510000, 1665000, 5000))\n",
        "# to_check.append(425000)\n",
        "for c in to_check:\n",
        "  print(c)"
      ],
      "metadata": {
        "id": "zdK__RW_RWQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33af6aab-83dd-4f47-efd9-1a3c8f940ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1510000\n",
            "1515000\n",
            "1520000\n",
            "1525000\n",
            "1530000\n",
            "1535000\n",
            "1540000\n",
            "1545000\n",
            "1550000\n",
            "1555000\n",
            "1560000\n",
            "1565000\n",
            "1570000\n",
            "1575000\n",
            "1580000\n",
            "1585000\n",
            "1590000\n",
            "1595000\n",
            "1600000\n",
            "1605000\n",
            "1610000\n",
            "1615000\n",
            "1620000\n",
            "1625000\n",
            "1630000\n",
            "1635000\n",
            "1640000\n",
            "1645000\n",
            "1650000\n",
            "1655000\n",
            "1660000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we evaluated all checkpoints to find the best configuration. We saved all the predictions in a folder (named like the current context)\n",
        "output_folder='gs://bucket_context/eighth_experiment/final_best_checkpoint_eval/{}'.format(config)\n",
        "\n",
        "# we used model.predict function (setting beam_size)\n",
        "import os\n",
        "input_file='gs://bucket_context/eighth_experiment/ft_final_model_{}/validation_eval/ft_inputs'.format(config)\n",
        "# you can keep the same output file; by default when predicting it added the number of steps so the file is not overwritten\n",
        "output_file=os.path.join(output_folder, \"predictions.txt\")\n",
        "print(output_file)\n",
        "print(input_file)\n",
        "\n",
        "\n",
        "from t5.seqio import SentencePieceVocabulary\n",
        "\n",
        "vocabulary_predict=load_vocabulary()\n",
        "\n",
        "model.batch_size = 128\n",
        "\n",
        "for checkpoint in to_check:\n",
        "  print(checkpoint)\n",
        "  model.predict(input_file=input_file, output_file=output_file,\n",
        "                checkpoint_steps=checkpoint, beam_size=1, temperature=0.0, keep_top_k=-1, vocabulary=vocabulary_predict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47aUJoKPDxfC",
        "outputId": "07c93ae4-3cb8-4893-a39a-2f7599ab3021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://bucket_context/eighth_experiment/final_best_checkpoint_eval/most_similar_crystalbleu/predictions.txt\n",
            "gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/validation_eval/ft_inputs\n",
            "1510000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1515000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1520000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1525000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1530000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1535000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1540000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1545000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1550000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1555000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1560000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1565000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1570000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1575000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1580000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1585000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1590000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1595000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1600000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1605000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1610000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1615000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1620000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1625000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1630000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1635000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1640000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1645000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1650000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1655000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:root:system_path_file_exists:gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_context/eighth_experiment/ft_final_model_most_similar_crystalbleu/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1660000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_Qs1dzBV9h5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}